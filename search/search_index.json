{"config":{"lang":["en","de"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"mesa_docs/","title":"Mesa","text":"<p>See the official Mesa documentation for detailed information.</p>"},{"location":"mesa_docs/#a-python-library-for-agent-based-modeling","title":"A Python Library for Agent-Based Modeling","text":"<p>Mesa<sup>1</sup> is a Python library designed for creating agent-based models (ABMs)<sup>2</sup>.  It provides tools to define, run, and visualize models in which individual entities, called agents, interact within an environment (the model).  Mesa is highly flexible, allowing to simulate complex systems and observe emergent behaviors arising from simple rules.</p>"},{"location":"mesa_docs/#agent-based-modeling-and-complex-societal-questions","title":"Agent-Based Modeling and Complex Societal Questions","text":"<p>Multi-agent-based simulation is a valuable tool to research voting rules and collective decision-making as it allows for the modeling of very complex interactions that are challenging to capture with traditional methods<sup>3</sup>. ABM is mainly used to research and analyze complex relationships.  The focus is on understanding how individual behaviors and interactions lead to collective outcomes.  It is often used in fields like social sciences, economics,  and environmental science to model and analyze scenarios that are impractical to study otherwise.</p> <p> Figure 1: Example of a simple Schelling-Model in Mesa</p> <ol> <li> <p>Jackie Kazil, David Masad, and Andrew Crooks. Utilizing Python for Agent-Based Modeling: The Mesa Framework. In: Social, Cultural, and Behavioral Modeling. Ed. by Robert Thomson, Halil Bisgin, Christopher Dancy, Ayaz Hyder, and Muhammad Hussain. Cham: Springer International Publishing, 2020, pp. 308\u2013317\u00a0\u21a9</p> </li> <li> <p>Dirk Helbing. Agent-based modeling. In: Social self-organization: Agent-based simulations and experiments to study emergent social behavior. Springer, 2012, pp. 25\u201370\u00a0\u21a9</p> </li> <li> <p>Robert L Axtell and J Doyne Farmer. Agent-based modeling in economics and finance: Past, present, and future. In: Journal of Economic Literature (2022), pp. 1\u201310\u00a0\u21a9</p> </li> </ol>"},{"location":"teaser/","title":"Navigating the Future: The Role of Democratic Governance to Solve Global Challenges and AI Risks","text":"<p>In a world brimming with complexities and uncertainties, we find ourselves at a crossroads.  We face a myriad of pressing global challenges \u2014 from climate change<sup>9</sup> and social inequality<sup>8</sup>  to the ethical dilemmas posed by the rapid advancement of artificial intelligence (AI)<sup>4</sup>.</p> <p>Imagine a future where AI surpasses individual human intelligence across many domains<sup>3</sup>. How do we safely integrate this expertise into existing governance structures? At present, AI algorithms, mostly devoid of ethical considerations, perpetuate biases<sup>5</sup> and render decisions  that lack transparency or foresight<sup>2</sup>.  How can we harness this burgeoning power effectively while mitigating its risks?</p> <p>If you were forced to give a single solution to all the world's most pressing problems, what would it be? Universal education? Innovation and Technology? Or even AI?</p>"},{"location":"teaser/#the-imperative-of-collective-intelligence","title":"The Imperative of Collective Intelligence","text":"<p>I posit that \"enhancing governance\" is the linchpin around which all solutions revolve.  In other words, we must elevate our collective intelligence<sup>6</sup> above all else  to safely and effectively navigate our future.</p> <p>In an era increasingly defined by the advent of general AI,  we have more reason than ever to focus on democratizing governance  and aligning AI development symbiotically within it<sup>7</sup>. Because at the heart of the AI dilemma lies the need for ethical decision-making and strategic planning \u2014 a terrain  where AI's weaknesses are most pronounced. The principles of democratic governance offer a sturdy foundation,  providing the checks and balances necessary to guide AI development in line with human values and long-term welfare.</p> <p></p> <p>However, the importance of democratic decision-making transcends the realm of AI.  It extends to our collective response to all global challenges, ensuring policies are inclusive,  coherent, and accountable. Democratic governance fosters economic stability, social justice, and  environmental stewardship \u2014 essential ingredients for navigating the complexities of the 21st century.</p>"},{"location":"teaser/#using-multi-agent-based-simulations","title":"Using Multi-Agent-Based Simulations","text":"<p>To embark on improving governance, we must first delve into research.  Traditionally, collective decision-making research has focused  on evaluating methods against reasonable assumptions (like Pareto optimality, Condorcet consistency,  non-dictatorship, etc.), demonstrating mathematically that no method will ever satisfy all criteria<sup>1</sup>.  But the complexity of the problem is even greater when we consider collective decision-making in real-world societies. Real-world democratic governance goes far beyond merely aligning individual interests \u2014 it involves intricate  path dependencies from past decisions, disinformation and lack of participation, to name just the most obvious.</p> <p>Addressing these challenges requires a novel approach.  This research aims to pioneer a new path by incorporating these complexities through multi-agent-based simulations.</p> <p>While the model and research inquiries within the proposed master thesis  can only represent this approach in its infancy, the potential of multi-agent-based modeling  to eventually encapsulate all essential facets of real-world democratic governance can hardly be overstated<sup>10</sup>. To the best of our knowledge, this approach has not been systematically applied to researching social choice  or collective decision-making. It stands poised to boost what may be the most underestimated cornerstone of human society: our collective intelligence.</p>"},{"location":"teaser/#references","title":"References","text":"<ol> <li> <p>Felix Brandt, Vincent Conitzer, Ulle Endriss, J\u00e9r\u00f4me Lang, and Ariel D. Procaccia, editors. Handbook of Computational Social Choice. Cambridge University Press, 2016\u00a0\u21a9</p> </li> <li> <p>Jana Fehr, Brian Citro, Rohit Malpani, Christoph Lippert, and Vince I Madai. A trustworthy AI reality-check: the lack of transparency of artificial intelligence products in healthcare. Frontiers in Digital Health, 6:1267290, 2024.\u00a0\u21a9</p> </li> <li> <p>Katja Grace, John Salvatier, Allan Dafoe, Baobao Zhang, and Owain Evans. Viewpoint: When will AI exceed human performance? evidence from AI experts. J. Artif. Intell. Res., 62:729\u2013754, 2018.\u00a0\u21a9</p> </li> <li> <p>Benjamin Hilton. Preventing an AI-related catastrophe: AI might bring huge benefits \u2014 if we avoid the risks.\u00a0\u21a9</p> </li> <li> <p>Susan Leavy, Barry O\u2019Sullivan, and Eugenia Siapera. Data, power and bias in artificial intelligence. CoRR, abs/2008.07341, 2020.\u00a0\u21a9</p> </li> <li> <p>Jan Marco Leimeister. Collective intelligence. Business &amp; Information Systems Engineering, 2:245\u2013248, 2010.\u00a0\u21a9</p> </li> <li> <p>Thomas W Malone. Superminds: The surprising power of people and computers thinking together. Little, Brown Spark, 2018.\u00a0\u21a9</p> </li> <li> <p>Thomas Piketty. Das Kapital im 21. Jahrhundert. CH Beck, 2014.\u00a0\u21a9</p> </li> <li> <p>Hans-Otto P\u00f6rtner, Debra C Roberts, H Adams, C Adler, P Aldunce, E Ali, R Ara Begum, R Betts, R Bezner Kerr, R Biesbroek, et al. Climate change 2022: Impacts, adaptation and vulnerability. IPCC Sixth Assessment Report, 2022.\u00a0\u21a9</p> </li> <li> <p>Robert L Axtell and J Doyne Farmer. Agent-based modeling in economics and finance: Past, present, and future. In: Journal of Economic Literature (2022), pp. 1\u201310\u00a0\u21a9</p> </li> </ol>"},{"location":"research/goals/","title":"Goals","text":"<p>DemocracySim is a multi-agent simulation framework designed to explore the effects of different voting rules on democratic participation and welfare.  Its broader aim is to be able to include complex and diverse factors via simulation to investigate how collective decision-making processes can be improved.  With a focus on agent-based modeling, the simulation ties together elements of participatory dynamics, resource allocation, and group decision effects in a controlled, evolving system.</p>"},{"location":"research/goals/#research-questions","title":"Research Questions","text":"<p>DemocracySim seeks to answer several critical questions:</p> <ul> <li>Do different voting procedures produce varying dynamics, and if so, how?</li> <li>How do minority and majority agent types behave in collective decision-making?</li> <li>What are the long-term effects of (non-)participation on the system?</li> <li>How does wealth distribution impact participation and welfare in the simulation?</li> </ul>"},{"location":"research/goals/#broader-implications","title":"Broader Implications","text":"<p>This project offers a controlled testbed for understanding the complex interplay of individual and collective interest in democratic systems. DemocracySim has the potential to reveal valuable insights into real-world voting dynamics.</p>"},{"location":"research/metrics/","title":"Metrics","text":""},{"location":"research/metrics/#simulation-metrics-indicators","title":"Simulation Metrics / Indicators","text":""},{"location":"research/metrics/#participation-rate-aggregate-behavioral-variable","title":"Participation Rate (Aggregate Behavioral Variable)","text":"<ul> <li>Measures the percentage of agents actively participating in elections at a given time.</li> <li>Helps evaluate the participation dilemma by analyzing participation across the group and comparing rates for majority vs. minority groups.</li> </ul>"},{"location":"research/metrics/#altruism-factor-individual-behavioral-variable","title":"Altruism Factor (Individual Behavioral Variable)","text":"<ul> <li>Quantifies the extent to which agents prioritize the collective good (e.g., the group's accuracy in guessing) over individual preferences, including cases of non-cooperation with a majority they belong to when it conflicts with the (expected) collective good.</li> <li>Additionally, tracking the average altruism factor of personality groups can provide insights, though this may be misleading if agents/groups do not participate.</li> </ul>"},{"location":"research/metrics/#gini-index-inequality-metric","title":"Gini Index (Inequality Metric)","text":"<ul> <li>Measures the inequality in asset distribution among agents within the system.</li> <li>Ranges from 0 (perfect equality) to 1 (maximum inequality, where one agent holds all assets).</li> <li>Offers insights into how electoral decisions impact wealth/resource distribution over time.</li> </ul>"},{"location":"research/metrics/#collective-accuracy","title":"Collective Accuracy","text":"<ul> <li>Measures how accurately the group, as a collective, estimates the actual color distribution.</li> <li>This directly influences rewards and serves as a metric for evaluating group performance against a ground truth.</li> </ul>"},{"location":"research/metrics/#diversity-of-shared-opinions","title":"Diversity of Shared Opinions","text":"<ul> <li>Evaluates the variation in agents' expressed preferences.</li> <li>To track whether participating agents provide diverse input or converge on overly similar opinions (e.g., due to majority influence).</li> </ul>"},{"location":"research/metrics/#distance-to-optimum","title":"Distance to Optimum","text":"<p>In principle, the optimal decision can be determined based on a predefined goal, allowing the distance between this optimum and the group's actual decision to be measured.</p> <p>Possible predefined goals include:</p> <ol> <li> <p>Utilitarian:</p> <ul> <li>Maximize the total sum of distributed rewards.</li> <li>Focus on the total reward, regardless of how it is distributed.</li> </ul> </li> <li> <p>Egalitarian:</p> <ul> <li>Minimize the overall inequality in individual rewards.</li> <li>Focus on fairness, aiming for a more just distribution of rewards among members.</li> </ul> </li> <li> <p>Rawlsian:</p> <ul> <li>Maximize the rewards for the poorest (personality-based) group.</li> <li>Inspired by John Rawls' Difference Principle, the focus is on improving the well-being of the least advantaged group while tolerating inequalities elsewhere.</li> </ul> </li> </ol>"},{"location":"research/research_concept/","title":"Concept","text":"<p>DemocracySim is set in a grid-based environment where agents interact with their surroundings and participate in group decision-making through elections. The system explores various scenarios and voting rules to understand key dynamics and challenges in democratic participation.</p>"},{"location":"research/research_concept/#key-features","title":"Key Features","text":""},{"location":"research/research_concept/#simulated-environment","title":"Simulated Environment:","text":"<ul> <li>The grid is designed without boundaries, and each unit (field) within it adopts one of x colors. Fields change color based on election results, with a mutation rate affected by prior outcomes.</li> <li>Groups of fields form territories, which serve as the basis for elections and influence grid evolution.</li> </ul>"},{"location":"research/research_concept/#agents","title":"Agents:","text":"<ul> <li>Agents are equipped with a basic artificial intelligence system and operate under a \"top-down\" model, learning decision-making strategies via training.</li> <li>Each agent has a limited budget and must decide whether to participate in elections.</li> <li>Agents have individual preferences over colors (called personalities) and are divided into y randomly distributed personality types. (The distribution of types forms majority-minority situations.)</li> </ul>"},{"location":"research/research_concept/#elections-and-rewards-two-dilemmas","title":"Elections and Rewards (Two Dilemmas):","text":"<ol> <li> <p>Elections:</p> <ul> <li>Elections concern the frequency distribution of field colors in a given territory, representing an \"objective truth\" aimed at emulating wise group decisions.</li> <li>For an intuitive understanding, the election addresses the question: \"What is \u2014 or should be \u2014 the current color distribution within your territory?\"</li> </ul> </li> <li> <p>Rewards:</p> <ul> <li>Rewards are distributed to all agents in the territory, regardless of participation (participation dilemma).   These rewards consist of:<ul> <li>Base reward: Distributed equally based on how well agents guess the true color distribution.</li> <li>Personal reward: Allocated based on the alignment between election results and agent preferences, introducing a second dilemma:<ul> <li>Should agents vote selfishly (favoring their preferences) or vote with a focus on the group's accuracy (collective good)?</li> </ul> </li> </ul> </li> </ul> </li> </ol>"},{"location":"technical/approval_voting/","title":"Problem of threshold in approval voting","text":"<p>If we choose an architecture in which voters always provide a sum-normalized preference vector for all voting rules, then approval voting has to have a threshold value to determine which options are approved. This may take autonomy away from the voters, but it ensures that every voting rule is based on the same conditions increasing comparability. It may also help to add more rules later on.</p>"},{"location":"technical/approval_voting/#idea","title":"Idea","text":"<p>Setting a fixed threshold of $ \\frac{1}{m} $ for approval voting where m is the number of options.</p>"},{"location":"technical/approval_voting/#definitions-and-setup","title":"Definitions and Setup","text":"<ul> <li>Sum-normalized vector: A preference vector $ \\mathbf{p} = (p_1, p_2, \\ldots, p_m) $ where each entry $ p_i $ represents the preference score for option $ i $, with the constraint $ \\sum_{i=1}^m p_i = 1 $.</li> <li>Threshold: A fixed threshold of $ \\frac{1}{m} $ is used to determine approval. If $ p_i \\geq \\frac{1}{m} $, the option $ i $ is considered \"approved.\"</li> </ul>"},{"location":"technical/approval_voting/#average-number-of-approved-values","title":"Average Number of Approved Values","text":"<p>To find the average number of values approved, let's consider how many entries $ p_i $ would meet the threshold $ p_i \\geq \\frac{1}{m} $.</p> <ol> <li>Expectation Calculation:</li> <li>The expected number of approvals can be found by looking at the expected value of each $ p_i $ being greater than or equal to $ \\frac{1}{m} $.</li> <li> <p>For a sum-normalized vector, the average value of any $ p_i $ is $ \\frac{1}{m} $. This is because the sum of all entries equals 1, and there are $ m $ entries.</p> </li> <li> <p>Probability of Approval:</p> </li> <li> <p>If the vector entries are randomly distributed, the probability of any given $ p_i $ being above the threshold is approximately 50%. This stems from the fact that the mean is $ \\frac{1}{m} $, and assuming a uniform or symmetric distribution around this mean, half the entries would be above, and half below, in expectation.</p> </li> <li> <p>Expected Number of Approvals:</p> </li> <li>Since each entry has a 50% chance of being above $ \\frac{1}{m} $ in a uniform random distribution, the expected number of approved values is $ \\frac{m}{2} $.</li> </ol> <p>Therefore, on average, $ \\frac{m}{2} $ values will be approved.</p>"},{"location":"technical/approval_voting/#range-of-the-number-of-approved-values","title":"Range of the Number of Approved Values","text":"<p>The number of approved values can vary depending on how the preference scores are distributed. Here's the possible range:</p> <ol> <li>Minimum Approved Values:</li> <li> <p>If all entries are below $ \\frac{1}{m} $, then none would be approved. However, given the constraint that the vector sums to 1, at least one entry must be $ \\frac{1}{m} $ or higher. Hence, the minimum number of approved values is 1.</p> </li> <li> <p>Maximum Approved Values:</p> </li> <li>The maximum occurs when as many values as possible are at least $ \\frac{1}{m} $. In the extreme case, you could have all $ m $ entries equal $ \\frac{1}{m} $ exactly, making them all approved. Thus, the maximum number of approved values is m.</li> </ol>"},{"location":"technical/approval_voting/#conclusion","title":"Conclusion","text":"<ul> <li>Average number of approved values: $ \\frac{m}{2} $.</li> <li>Range of approved values: From 1 (minimum) to $ m $ (maximum).</li> </ul> <p>Hence, in theory, voters can still approve between 1 and $ m $ options,  giving them the whole range of flexibility that approval voting offers.</p>"},{"location":"technical/approval_voting/#possibility-for-improvement","title":"Possibility for improvement","text":"<p>We should consider implementing rule-specific voting into the agent's decision-making process instead of leaving all rule-specifics to the aggregation process. This would allow for a more realistic comparison of the rules. For some rules, it would also give opportunities to significantly speed up the simulation process.</p>"},{"location":"technical/preference_relations/","title":"How preference relations are defined and represented in the system","text":""},{"location":"technical/preference_relations/#introduction","title":"Introduction","text":"<p>...</p>"},{"location":"technical/preference_relations/#definition","title":"Definition","text":"<p>A preference relation \\tau\\in\\mathbb{R}_{\\geq 0}^m is a numpy vector of length m,  where m is the number of options and each element \\tau[i] represents the normalized preference for option i, with \\sum_{\\tau}=1.</p>"},{"location":"technical/preference_relations/#why-using-sum-normalization","title":"Why using sum normalization?","text":"<p>In computational social choice, sum normalization is more common than magnitude normalization.  This is because sum normalization aligns well with the interpretation of preference vectors as distributions  or weighted votes, which are prevalent in social choice scenarios.</p>"},{"location":"technical/preference_relations/#why-using-non-negative-values","title":"Why using non-negative values?","text":"<p>The preference values \\tau[i] are non-negative because they represent the strength of preference for each option. Equvalently, they can be interpreted as the probability of selecting each option  or the (inverted or negative) distance of an option to the agents' ideal solution.</p>"},{"location":"technical/technical_overview/","title":"Technical overview","text":"<p>DemocracySim is a multi-agent simulation framework designed to examine democratic participation.  This project models agents (with personal interests forming majority-minority groups), environments  (evolving under the influence of the collective behavior of the agents),  and elections to analyze how voting rules influence participation,  welfare, system dynamics and overall collective outcomes.</p> <p>Key features:</p> <ul> <li>Multi-agent system simulation using Mesa framework.</li> <li>Grid-based environment with wrap-around support (toroidal topology).</li> <li>Explore societal outcomes under different voting rules.</li> </ul>"},{"location":"technical/technical_overview/#features","title":"Features","text":"<ul> <li>Agents:</li> <li>Independently acting entities modeled with preferences, budgets, and decision-making strategies.</li> <li>Can participate in elections, have personal preferences and limited information about surroundings.</li> <li> <p>Trained with decision-tree methods to simulate behavior.</p> </li> <li> <p>Environment:</p> </li> <li>Structured as a grid divided into \"territories\" or \"areas.\"</li> <li>A single unit of the grid is a \"cell\" or \"field.\"</li> <li> <p>Each cell has a specific \"color\" representing a state. Elections influence these states, and areas mutate over time.</p> </li> <li> <p>Metrics:</p> </li> <li>Participation rates, altruism factors, and metrics such as the Gini Index to analyze inequalities and long-term trends.</li> </ul> <p>Learn more in the following sections.</p>"},{"location":"technical/api/Area/","title":"Class <code>Area</code>","text":"<p>               Bases: <code>Agent</code></p> Source code in <code>democracy_sim/participation_model.py</code> <pre><code>class Area(mesa.Agent):\n    def __init__(self, unique_id, model, height, width, size_variance):\n        \"\"\"\n        Create a new area.\n\n        Attributes:\n            unique_id (int): The unique identifier of the area.\n            model (ParticipationModel): The simulation model of which the area is part of.\n            height (int): The average height of the area (see size_variance).\n            width (int): The average width of the area (see size_variance).\n            size_variance (float): A variance factor applied to height and width.\n        \"\"\"\n        if TYPE_CHECKING:  # Type hint for IDEs\n            model = cast(ParticipationModel, model)\n        super().__init__(unique_id=unique_id,  model=model)\n        self._set_dimensions(width, height, size_variance)\n        self.agents = []\n        self._personality_distribution = None\n        self.cells = []\n        self._idx_field = None  # An indexing position of the area in the grid\n        self._color_distribution = np.zeros(model.num_colors) # Initialize to 0\n        self._voted_ordering = None\n        self._voter_turnout = 0  # In percent\n        self._dist_to_reality = None  # Elected vs. actual color distribution\n\n    def __str__(self):\n        return (f\"Area(id={self.unique_id}, size={self._height}x{self._width}, \"\n                f\"at idx_field={self._idx_field}, \"\n                f\"num_agents={self.num_agents}, num_cells={self.num_cells}, \"\n                f\"color_distribution={self.color_distribution})\")\n\n    def _set_dimensions(self, width, height, size_var):\n        \"\"\"\n        Sets the area's dimensions based on the provided width, height, and variance factor.\n\n        This function adjusts the width and height by a random factor drawn from\n        the range [1 - size_var, 1 + size_var]. If size_var is zero, no variance\n        is applied.\n\n        Args:\n            width (int): The average width of the area.\n            height (int): The average height of the area.\n            size_var (float): A variance factor applied to width and height.\n                Must be in [0, 1].\n\n        Raises:\n            ValueError: If size_var is not between 0 and 1.\n        \"\"\"\n        if size_var == 0:\n            self._width = width\n            self._height = height\n            self.width_off, self.height_off = 0, 0\n        elif size_var &gt; 1 or size_var &lt; 0:\n            raise ValueError(\"Size variance must be between 0 and 1\")\n        else:  # Apply variance\n            w_var_factor = self.random.uniform(1 - size_var, 1 + size_var)\n            h_var_factor = self.random.uniform(1 - size_var, 1 + size_var)\n            self._width = int(width * w_var_factor)\n            self.width_off = abs(width - self._width)\n            self._height = int(height * h_var_factor)\n            self.height_off = abs(height - self._height)\n\n    @property\n    def num_agents(self):\n        return len(self.agents)\n\n    @property\n    def num_cells(self):\n        return self._width * self._height\n\n    @property\n    def personality_distribution(self):\n        return self._personality_distribution\n\n    @property\n    def color_distribution(self):\n        return self._color_distribution\n\n    @property\n    def voted_ordering(self):\n        return self._voted_ordering\n\n    @property\n    def voter_turnout(self):\n        return self._voter_turnout\n\n    @property\n    def dist_to_reality(self):\n        return self._dist_to_reality\n\n    @property\n    def idx_field(self):\n        return self._idx_field\n\n    @idx_field.setter\n    def idx_field(self, pos: tuple):\n        \"\"\"\n        Sets the indexing field (cell coordinate in the grid) of the area.\n\n        This method sets the areas indexing-field (top-left cell coordinate)\n        which determines which cells and agents on the grid belong to the area.\n        The cells and agents are added to the area's lists of cells and agents.\n\n        Args:\n            pos: (x, y) representing the areas top-left coordinates.\n        \"\"\"\n        # TODO: Check - isn't it better to make sure agents are added to the area when they are created?\n        # TODO -- There is something wrong here!!! (Agents are not added to the areas)\n        if TYPE_CHECKING:  # Type hint for IDEs\n            self.model = cast(ParticipationModel, self.model)\n        try:\n            x_val, y_val = pos\n        except ValueError:\n            raise ValueError(\"The idx_field must be a tuple\")\n        # Check if the values are within the grid\n        if x_val &lt; 0 or x_val &gt;= self.model.width:\n            raise ValueError(f\"The x={x_val} value must be within the grid\")\n        if y_val &lt; 0 or y_val &gt;= self.model.height:\n            raise ValueError(f\"The y={y_val} value must be within the grid\")\n        x_off = self.width_off // 2\n        y_off = self.height_off // 2\n        # Adjusting indices with offset and ensuring they wrap around the grid\n        adjusted_x = (x_val + x_off) % self.model.width\n        adjusted_y = (y_val + y_off) % self.model.height\n        # Assign the cells to the area\n        for x_area in range(self._width):\n            for y_area in range(self._height):\n                x = (adjusted_x + x_area) % self.model.width\n                y = (adjusted_y + y_area) % self.model.height\n                cell = self.model.grid.get_cell_list_contents([(x, y)])[0]\n                if TYPE_CHECKING:\n                    cell = cast(ColorCell, cell)\n                self.add_cell(cell)  # Add the cell to the area\n                # Add all voting agents to the area\n                for agent in cell.agents:\n                    self.add_agent(agent)\n                cell.add_area(self)  # Add the area to the color-cell\n                # Mark as a border cell if true\n                if (x_area == 0 or y_area == 0\n                        or x_area == self._width - 1\n                        or y_area == self._height - 1):\n                    cell.is_border_cell = True\n        self._idx_field = (adjusted_x, adjusted_y)\n        self._update_color_distribution()\n        self._update_personality_distribution()\n\n    def _update_personality_distribution(self) -&gt; None:\n        \"\"\"\n        This method calculates the areas current distribution of personalities.\n        \"\"\"\n        personalities = list(self.model.personalities)\n        p_counts = {str(i): 0 for i in personalities}\n        # Count the occurrence of each personality\n        for agent in self.agents:\n            p_counts[str(agent.personality)] += 1\n        # Normalize the counts\n        self._personality_distribution = [p_counts[str(p)] / self.num_agents\n                                          for p in personalities]\n\n    def add_agent(self, agent: VoteAgent) -&gt; None:\n        \"\"\"\n        Appends an agent to the areas agents list.\n\n        Args:\n            agent (VoteAgent): The agent to be added to the area.\n        \"\"\"\n        self.agents.append(agent)\n\n    def add_cell(self, cell: ColorCell) -&gt; None:\n        \"\"\"\n        Appends a cell to the areas cells list.\n\n        Args:\n            cell (ColorCell): The agent to be added to the area.\n        \"\"\"\n        self.cells.append(cell)\n\n\n    def _conduct_election(self) -&gt; int:\n        \"\"\"\n        Simulates the election within the area and manages rewards.\n\n        The election process asks agents to participate, collects votes,\n        aggregates preferences using the model's voting rule,\n        and saves the elected option as the latest winning option.\n        Agents incur costs for participation\n        and may receive rewards based on the outcome.\n\n        Returns:\n            int: The voter turnout in percent. Returns 0 if no agent participates.\n        \"\"\"\n        # Ask agents for participation and their votes\n        preference_profile = self._tally_votes()\n        # Check for the case that no agent participated\n        if preference_profile.ndim != 2:\n            print(\"Area\", self.unique_id, \"no one participated in the election\")\n            return 0  # TODO: What to do in this case? Cease the simulation?\n        # Aggregate the preferences \u21d2 returns an option ordering\n        aggregated = self.model.voting_rule(preference_profile)\n        # Save the \"elected\" ordering in self._voted_ordering\n        winning_option = aggregated[0]\n        self._voted_ordering = self.model.options[winning_option]\n        # Calculate and distribute rewards\n        self._distribute_rewards()\n        # TODO check whether the current color dist and the mutation of the\n        #  colors is calculated and applied correctly and does not interfere\n        #  in any way with the election process\n        # Statistics\n        n = preference_profile.shape[0]  # Number agents participated\n        return int((n / self.num_agents) * 100) # Voter turnout in percent\n\n    def _tally_votes(self):\n        \"\"\"\n        Gathers votes from agents who choose to (and can afford to) participate.\n\n        Each participating agent contributes a vector of dissatisfaction values with\n        respect to the available options. These values are combined into a NumPy array.\n\n        Returns:\n            np.ndarray: A 2D array representing the preference profiles of all\n                participating agents. Each row corresponds to an agent's vote.\n        \"\"\"\n        preference_profile = []\n        for agent in self.agents:\n            model = self.model\n            el_costs = model.election_costs\n            # Give agents their (new) known fields\n            agent.update_known_cells(area=self)\n            if (agent.assets &gt;= el_costs\n                    and agent.ask_for_participation(area=self)):\n                agent.num_elections_participated += 1\n                # Collect the participation fee\n                agent.assets = agent.assets - el_costs\n                # Ask the agent for her preference\n                preference_profile.append(agent.vote(area=self))\n                # agent.vote returns an array containing dissatisfaction values\n                # between 0 and 1 for each option, interpretable as rank values.\n        return np.array(preference_profile)\n\n    def _distribute_rewards(self) -&gt; None:\n        \"\"\"\n        Calculates and distributes rewards (or penalties) to agents based on outcomes.\n\n        The function measures the difference between the actual color distribution\n        and the elected outcome using a distance metric. It then increments or reduces\n        agent assets accordingly, ensuring assets do not fall below zero.\n        \"\"\"\n        model = self.model\n        # Calculate the distance to the real distribution using distance_func\n        real_color_ord = np.argsort(self.color_distribution)[::-1]  # Descending\n        dist_func = model.distance_func\n        self._dist_to_reality = dist_func(real_color_ord, self.voted_ordering,\n                                          model.color_search_pairs)\n        # Calculate the rpa - rewards per agent (can be negative)\n        rpa = (0.5 - self.dist_to_reality) * model.max_reward  # TODO: change this (?)\n        # Distribute the two types of rewards\n        color_search_pairs = model.color_search_pairs\n        for a in self.agents:\n            # Personality-based reward factor\n            p = dist_func(a.personality, real_color_ord, color_search_pairs)\n            # + common reward (reward_pa) for all agents\n            a.assets = int(a.assets + (0.5 - p) * model.max_reward + rpa)\n            if a.assets &lt; 0:  # Correct wealth if it fell below zero\n                a.assets = 0\n\n    def _update_color_distribution(self) -&gt; None:\n        \"\"\"\n        Recalculates the area's color distribution and updates the _color_distribution attribute.\n\n        This method counts how many cells of each color belong to the area, normalizes\n        the counts by the total number of cells, and stores the result internally.\n        \"\"\"\n        color_count = {}\n        for cell in self.cells:\n            color = cell.color\n            color_count[color] = color_count.get(color, 0) + 1\n        for color in range(self.model.num_colors):\n            dist_val = color_count.get(color, 0) / self.num_cells  # Float\n            self._color_distribution[color] = dist_val\n\n    def _filter_cells(self, cell_list):\n        \"\"\"\n        This method is used to filter a given list of cells to return only\n        those which are within the area.\n\n        Args:\n            cell_list: A list of ColorCell cells to be filtered.\n\n        Returns:\n            A list of ColorCell cells that are within the area.\n        \"\"\"\n        cell_set = set(self.cells)\n        return [c for c in cell_list if c in cell_set]\n\n    def step(self) -&gt; None:\n        \"\"\"\n        Run one step of the simulation.\n\n        Conduct an election in the area,\n        mutate the cells' colors according to the election outcome\n        and update the color distribution of the area.\n        \"\"\"\n        self._voter_turnout = self._conduct_election()  # The main election logic!\n        if self.voter_turnout == 0:\n            return  # TODO: What to do if no agent participated..?\n\n        # Mutate colors in cells\n        # Take some number of cells to mutate (i.e., 5 %)\n        n_to_mutate = int(self.model.mu * self.num_cells)\n        # TODO/Idea: What if the voter_turnout determines the mutation rate?\n        # randomly select x cells\n        cells_to_mutate = self.random.sample(self.cells, n_to_mutate)\n        # Use voted ordering to pick colors in descending order\n        # To pre-select colors for all cells to mutate\n        # TODO: Think about this: should we take local color-structure\n        #  into account - like in color patches - to avoid colors mutating into\n        #  very random structures? # Middendorf\n        colors = np.random.choice(self.voted_ordering, size=n_to_mutate,\n                                  p=self.model.color_probs)\n        # Assign the newly selected colors to the cells\n        for cell, color in zip(cells_to_mutate, colors):\n            cell.color = color\n        # Important: Update the color distribution (because colors changed)\n        self._update_color_distribution()\n</code></pre>"},{"location":"technical/api/Area/#democracy_sim.participation_model.Area.__init__","title":"<code>__init__(unique_id, model, height, width, size_variance)</code>","text":"<p>Create a new area.</p> <p>Attributes:</p> Name Type Description <code>unique_id</code> <code>int</code> <p>The unique identifier of the area.</p> <code>model</code> <code>ParticipationModel</code> <p>The simulation model of which the area is part of.</p> <code>height</code> <code>int</code> <p>The average height of the area (see size_variance).</p> <code>width</code> <code>int</code> <p>The average width of the area (see size_variance).</p> <code>size_variance</code> <code>float</code> <p>A variance factor applied to height and width.</p> Source code in <code>democracy_sim/participation_model.py</code> <pre><code>def __init__(self, unique_id, model, height, width, size_variance):\n    \"\"\"\n    Create a new area.\n\n    Attributes:\n        unique_id (int): The unique identifier of the area.\n        model (ParticipationModel): The simulation model of which the area is part of.\n        height (int): The average height of the area (see size_variance).\n        width (int): The average width of the area (see size_variance).\n        size_variance (float): A variance factor applied to height and width.\n    \"\"\"\n    if TYPE_CHECKING:  # Type hint for IDEs\n        model = cast(ParticipationModel, model)\n    super().__init__(unique_id=unique_id,  model=model)\n    self._set_dimensions(width, height, size_variance)\n    self.agents = []\n    self._personality_distribution = None\n    self.cells = []\n    self._idx_field = None  # An indexing position of the area in the grid\n    self._color_distribution = np.zeros(model.num_colors) # Initialize to 0\n    self._voted_ordering = None\n    self._voter_turnout = 0  # In percent\n    self._dist_to_reality = None  # Elected vs. actual color distribution\n</code></pre>"},{"location":"technical/api/Area/#democracy_sim.participation_model.Area.add_agent","title":"<code>add_agent(agent)</code>","text":"<p>Appends an agent to the areas agents list.</p> <p>Parameters:</p> Name Type Description Default <code>agent</code> <code>VoteAgent</code> <p>The agent to be added to the area.</p> required Source code in <code>democracy_sim/participation_model.py</code> <pre><code>def add_agent(self, agent: VoteAgent) -&gt; None:\n    \"\"\"\n    Appends an agent to the areas agents list.\n\n    Args:\n        agent (VoteAgent): The agent to be added to the area.\n    \"\"\"\n    self.agents.append(agent)\n</code></pre>"},{"location":"technical/api/Area/#democracy_sim.participation_model.Area.add_cell","title":"<code>add_cell(cell)</code>","text":"<p>Appends a cell to the areas cells list.</p> <p>Parameters:</p> Name Type Description Default <code>cell</code> <code>ColorCell</code> <p>The agent to be added to the area.</p> required Source code in <code>democracy_sim/participation_model.py</code> <pre><code>def add_cell(self, cell: ColorCell) -&gt; None:\n    \"\"\"\n    Appends a cell to the areas cells list.\n\n    Args:\n        cell (ColorCell): The agent to be added to the area.\n    \"\"\"\n    self.cells.append(cell)\n</code></pre>"},{"location":"technical/api/Area/#democracy_sim.participation_model.Area.step","title":"<code>step()</code>","text":"<p>Run one step of the simulation.</p> <p>Conduct an election in the area, mutate the cells' colors according to the election outcome and update the color distribution of the area.</p> Source code in <code>democracy_sim/participation_model.py</code> <pre><code>def step(self) -&gt; None:\n    \"\"\"\n    Run one step of the simulation.\n\n    Conduct an election in the area,\n    mutate the cells' colors according to the election outcome\n    and update the color distribution of the area.\n    \"\"\"\n    self._voter_turnout = self._conduct_election()  # The main election logic!\n    if self.voter_turnout == 0:\n        return  # TODO: What to do if no agent participated..?\n\n    # Mutate colors in cells\n    # Take some number of cells to mutate (i.e., 5 %)\n    n_to_mutate = int(self.model.mu * self.num_cells)\n    # TODO/Idea: What if the voter_turnout determines the mutation rate?\n    # randomly select x cells\n    cells_to_mutate = self.random.sample(self.cells, n_to_mutate)\n    # Use voted ordering to pick colors in descending order\n    # To pre-select colors for all cells to mutate\n    # TODO: Think about this: should we take local color-structure\n    #  into account - like in color patches - to avoid colors mutating into\n    #  very random structures? # Middendorf\n    colors = np.random.choice(self.voted_ordering, size=n_to_mutate,\n                              p=self.model.color_probs)\n    # Assign the newly selected colors to the cells\n    for cell, color in zip(cells_to_mutate, colors):\n        cell.color = color\n    # Important: Update the color distribution (because colors changed)\n    self._update_color_distribution()\n</code></pre>"},{"location":"technical/api/Area/#private-method","title":"Private Method","text":"<p>Simulates the election within the area and manages rewards.</p> <p>The election process asks agents to participate, collects votes, aggregates preferences using the model's voting rule, and saves the elected option as the latest winning option. Agents incur costs for participation and may receive rewards based on the outcome.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The voter turnout in percent. Returns 0 if no agent participates.</p> Source code in <code>democracy_sim/participation_model.py</code> <pre><code>def _conduct_election(self) -&gt; int:\n    \"\"\"\n    Simulates the election within the area and manages rewards.\n\n    The election process asks agents to participate, collects votes,\n    aggregates preferences using the model's voting rule,\n    and saves the elected option as the latest winning option.\n    Agents incur costs for participation\n    and may receive rewards based on the outcome.\n\n    Returns:\n        int: The voter turnout in percent. Returns 0 if no agent participates.\n    \"\"\"\n    # Ask agents for participation and their votes\n    preference_profile = self._tally_votes()\n    # Check for the case that no agent participated\n    if preference_profile.ndim != 2:\n        print(\"Area\", self.unique_id, \"no one participated in the election\")\n        return 0  # TODO: What to do in this case? Cease the simulation?\n    # Aggregate the preferences \u21d2 returns an option ordering\n    aggregated = self.model.voting_rule(preference_profile)\n    # Save the \"elected\" ordering in self._voted_ordering\n    winning_option = aggregated[0]\n    self._voted_ordering = self.model.options[winning_option]\n    # Calculate and distribute rewards\n    self._distribute_rewards()\n    # TODO check whether the current color dist and the mutation of the\n    #  colors is calculated and applied correctly and does not interfere\n    #  in any way with the election process\n    # Statistics\n    n = preference_profile.shape[0]  # Number agents participated\n    return int((n / self.num_agents) * 100) # Voter turnout in percent\n</code></pre>"},{"location":"technical/api/ColorCell/","title":"Class <code>ColorCell</code>","text":"<p>               Bases: <code>Agent</code></p> <p>Represents a single cell (a field in the grid) with a specific color.</p> <p>Attributes:</p> Name Type Description <code>color</code> <code>int</code> <p>The color of the cell.</p> Source code in <code>democracy_sim/participation_agent.py</code> <pre><code>class ColorCell(Agent):\n    \"\"\"\n    Represents a single cell (a field in the grid) with a specific color.\n\n    Attributes:\n        color (int): The color of the cell.\n    \"\"\"\n\n    def __init__(self, unique_id, model, pos: tuple, initial_color: int):\n        \"\"\"\n        Initializes a ColorCell, at the given row, col position.\n\n        Args:\n            unique_id (int): The unique identifier of the cell.\n            model (mesa.Model): The mesa model of which the cell is part of.\n            pos (Tuple[int, int]): The position of the cell in the grid.\n            initial_color (int): The initial color of the cell.\n        \"\"\"\n        super().__init__(unique_id, model)\n        # The \"pos\" variable in mesa is special, so I avoid it here\n        self._row = pos[0]\n        self._col = pos[1]\n        self.color = initial_color  # The cell's current color (int)\n        self._next_color = None\n        self.agents = []\n        self.areas = []\n        self.is_border_cell = False\n\n    def __str__(self):\n        return (f\"Cell ({self.unique_id}, pos={self.position}, \"\n                f\"color={self.color}, num_agents={self.num_agents_in_cell})\")\n\n    @property\n    def col(self):\n        \"\"\"The col location of this cell.\"\"\"\n        return self._col\n\n    @property\n    def row(self):\n        \"\"\"The row location of this cell.\"\"\"\n        return self._row\n\n    @property\n    def position(self):  # The variable pos is special in mesa!\n        \"\"\"The location of this cell.\"\"\"\n        return self._row, self._col\n\n    @property\n    def num_agents_in_cell(self):\n        \"\"\"The number of agents in this cell.\"\"\"\n        return len(self.agents)\n\n    def add_agent(self, agent):\n        self.agents.append(agent)\n\n    def remove_agent(self, agent):\n        self.agents.remove(agent)\n\n    def add_area(self, area):\n        self.areas.append(area)\n\n    def color_step(self):\n        \"\"\"\n        Determines the cells' color for the next step.\n        TODO\n        \"\"\"\n        # _neighbor_iter = self.model.grid.iter_neighbors(\n        #     (self._row, self._col), True)\n        # neighbors_opinion = Counter(n.get_state() for n in _neighbor_iter)\n        # # Following is a tuple (attribute, occurrences)\n        # polled_opinions = neighbors_opinion.most_common()\n        # tied_opinions = []\n        # for neighbor in polled_opinions:\n        #     if neighbor[1] == polled_opinions[0][1]:\n        #         tied_opinions.append(neighbor)\n        #\n        # self._next_color = self.random.choice(tied_opinions)[0]\n        pass\n\n    def advance(self):\n        \"\"\"\n        Set the state of the agent to the next state.\n        TODO\n        \"\"\"\n        # self._color = self._next_color\n        pass\n</code></pre>"},{"location":"technical/api/ColorCell/#democracy_sim.participation_agent.ColorCell.col","title":"<code>col</code>  <code>property</code>","text":"<p>The col location of this cell.</p>"},{"location":"technical/api/ColorCell/#democracy_sim.participation_agent.ColorCell.num_agents_in_cell","title":"<code>num_agents_in_cell</code>  <code>property</code>","text":"<p>The number of agents in this cell.</p>"},{"location":"technical/api/ColorCell/#democracy_sim.participation_agent.ColorCell.position","title":"<code>position</code>  <code>property</code>","text":"<p>The location of this cell.</p>"},{"location":"technical/api/ColorCell/#democracy_sim.participation_agent.ColorCell.row","title":"<code>row</code>  <code>property</code>","text":"<p>The row location of this cell.</p>"},{"location":"technical/api/ColorCell/#democracy_sim.participation_agent.ColorCell.__init__","title":"<code>__init__(unique_id, model, pos, initial_color)</code>","text":"<p>Initializes a ColorCell, at the given row, col position.</p> <p>Parameters:</p> Name Type Description Default <code>unique_id</code> <code>int</code> <p>The unique identifier of the cell.</p> required <code>model</code> <code>Model</code> <p>The mesa model of which the cell is part of.</p> required <code>pos</code> <code>Tuple[int, int]</code> <p>The position of the cell in the grid.</p> required <code>initial_color</code> <code>int</code> <p>The initial color of the cell.</p> required Source code in <code>democracy_sim/participation_agent.py</code> <pre><code>def __init__(self, unique_id, model, pos: tuple, initial_color: int):\n    \"\"\"\n    Initializes a ColorCell, at the given row, col position.\n\n    Args:\n        unique_id (int): The unique identifier of the cell.\n        model (mesa.Model): The mesa model of which the cell is part of.\n        pos (Tuple[int, int]): The position of the cell in the grid.\n        initial_color (int): The initial color of the cell.\n    \"\"\"\n    super().__init__(unique_id, model)\n    # The \"pos\" variable in mesa is special, so I avoid it here\n    self._row = pos[0]\n    self._col = pos[1]\n    self.color = initial_color  # The cell's current color (int)\n    self._next_color = None\n    self.agents = []\n    self.areas = []\n    self.is_border_cell = False\n</code></pre>"},{"location":"technical/api/ColorCell/#democracy_sim.participation_agent.ColorCell.advance","title":"<code>advance()</code>","text":"<p>Set the state of the agent to the next state. TODO</p> Source code in <code>democracy_sim/participation_agent.py</code> <pre><code>def advance(self):\n    \"\"\"\n    Set the state of the agent to the next state.\n    TODO\n    \"\"\"\n    # self._color = self._next_color\n    pass\n</code></pre>"},{"location":"technical/api/ColorCell/#democracy_sim.participation_agent.ColorCell.color_step","title":"<code>color_step()</code>","text":"<p>Determines the cells' color for the next step. TODO</p> Source code in <code>democracy_sim/participation_agent.py</code> <pre><code>def color_step(self):\n    \"\"\"\n    Determines the cells' color for the next step.\n    TODO\n    \"\"\"\n    # _neighbor_iter = self.model.grid.iter_neighbors(\n    #     (self._row, self._col), True)\n    # neighbors_opinion = Counter(n.get_state() for n in _neighbor_iter)\n    # # Following is a tuple (attribute, occurrences)\n    # polled_opinions = neighbors_opinion.most_common()\n    # tied_opinions = []\n    # for neighbor in polled_opinions:\n    #     if neighbor[1] == polled_opinions[0][1]:\n    #         tied_opinions.append(neighbor)\n    #\n    # self._next_color = self.random.choice(tied_opinions)[0]\n    pass\n</code></pre>"},{"location":"technical/api/Model/","title":"Class <code>ParticipationModel</code>","text":"<p>               Bases: <code>Model</code></p> <p>The ParticipationModel class provides a base environment for multi-agent simulations within a grid-based world (split into territories) that reacts dynamically to frequently held collective decision-making processes (\"elections\"). It incorporates voting agents with personalities, color cells (grid fields), and areas (election territories). This model is designed to analyze different voting rules and their impact.</p> <p>This class provides mechanisms for creating and managing cells, agents, and areas, along with data collection for analysis. Colors in the model mutate depending on a predefined mutation rate and are influenced by elections. Agents interact based on their personalities, knowledge, and experiences.</p> <p>Attributes:</p> Name Type Description <code>grid</code> <code>SingleGrid</code> <p>Grid representing the environment with a single occupancy per cell (the color).</p> <code>height</code> <code>int</code> <p>The height of the grid.</p> <code>width</code> <code>int</code> <p>The width of the grid.</p> <code>colors</code> <code>ndarray</code> <p>Array containing the unique color identifiers.</p> <code>voting_rule</code> <code>Callable</code> <p>A function defining the social welfare function to aggregate agent preferences. This callable typically takes agent rankings as input and returns a single aggregate result.</p> <code>distance_func</code> <code>Callable</code> <p>A function used to calculate a distance metric when comparing rankings. It takes two rankings and returns a numeric distance score.</p> <code>mu</code> <code>float</code> <p>Mutation rate; the probability of each color cell to mutate after an elections.</p> <code>color_probs</code> <code>ndarray</code> <p>Probabilities used to determine individual color mutation outcomes.</p> <code>options</code> <code>ndarray</code> <p>Matrix (array of arrays) where each subarray represents an option (color-ranking) available to agents.</p> <code>option_vec</code> <code>ndarray</code> <p>Array holding the indices of the available options for computational efficiency.</p> <code>color_cells</code> <code>list[ColorCell]</code> <p>List of all color cells. Initialized during the model setup.</p> <code>voting_agents</code> <code>list[VoteAgent]</code> <p>List of all voting agents. Initialized during the model setup.</p> <code>personalities</code> <code>list</code> <p>List of unique personalities available for agents.</p> <code>personality_distribution</code> <code>ndarray</code> <p>The (global) probability distribution of personalities among all agents.</p> <code>areas</code> <code>list[Area]</code> <p>List of areas (regions or territories within the grid) in which elections take place. Initialized during model setup.</p> <code>global_area</code> <code>Area</code> <p>The area encompassing the entire grid.</p> <code>av_area_height</code> <code>int</code> <p>Average height of areas in the simulation.</p> <code>av_area_width</code> <code>int</code> <p>Average width of areas created in the simulation.</p> <code>area_size_variance</code> <code>float</code> <p>Variance in area sizes to introduce non-uniformity among election territories.</p> <code>common_assets</code> <code>int</code> <p>Total resources to be distributed among all agents.</p> <code>av_area_color_dst</code> <code>ndarray</code> <p>Current (area)-average color distribution.</p> <code>election_costs</code> <code>float</code> <p>Cost associated with participating in elections.</p> <code>max_reward</code> <code>float</code> <p>Maximum reward possible for an agent each election.</p> <code>known_cells</code> <code>int</code> <p>Number of cells each agent knows the color of.</p> <code>datacollector</code> <code>DataCollector</code> <p>A tool for collecting data (metrics and statistics) at each simulation step.</p> <code>scheduler</code> <code>CustomScheduler</code> <p>The scheduler responsible for executing the step function.</p> <code>draw_borders</code> <code>bool</code> <p>Only for visualization (no effect on simulation).</p> <code>_preset_color_dst</code> <code>ndarray</code> <p>A predefined global color distribution (set randomly) that affects cell initialization globally.</p> Source code in <code>democracy_sim/participation_model.py</code> <pre><code>class ParticipationModel(mesa.Model):\n    \"\"\"\n    The ParticipationModel class provides a base environment for\n    multi-agent simulations within a grid-based world (split into territories)\n    that reacts dynamically to frequently held collective decision-making\n    processes (\"elections\"). It incorporates voting agents with personalities,\n    color cells (grid fields), and areas (election territories). This model is\n    designed to analyze different voting rules and their impact.\n\n    This class provides mechanisms for creating and managing cells, agents,\n    and areas, along with data collection for analysis. Colors in the model\n    mutate depending on a predefined mutation rate and are influenced by\n    elections. Agents interact based on their personalities, knowledge, and\n    experiences.\n\n    Attributes:\n        grid (mesa.space.SingleGrid): Grid representing the environment\n            with a single occupancy per cell (the color).\n        height (int): The height of the grid.\n        width (int): The width of the grid.\n        colors (ndarray): Array containing the unique color identifiers.\n        voting_rule (Callable): A function defining the social welfare\n            function to aggregate agent preferences. This callable typically\n            takes agent rankings as input and returns a single aggregate result.\n        distance_func (Callable): A function used to calculate a\n            distance metric when comparing rankings. It takes two rankings\n            and returns a numeric distance score.\n        mu (float): Mutation rate; the probability of each color cell to mutate\n            after an elections.\n        color_probs (ndarray):\n            Probabilities used to determine individual color mutation outcomes.\n        options (ndarray): Matrix (array of arrays) where each subarray\n            represents an option (color-ranking) available to agents.\n        option_vec (ndarray): Array holding the indices of the available options\n            for computational efficiency.\n        color_cells (list[ColorCell]): List of all color cells.\n            Initialized during the model setup.\n        voting_agents (list[VoteAgent]): List of all voting agents.\n            Initialized during the model setup.\n        personalities (list): List of unique personalities available for agents.\n        personality_distribution (ndarray): The (global) probability\n            distribution of personalities among all agents.\n        areas (list[Area]): List of areas (regions or territories within the\n            grid) in which elections take place. Initialized during model setup.\n        global_area (Area): The area encompassing the entire grid.\n        av_area_height (int): Average height of areas in the simulation.\n        av_area_width (int): Average width of areas created in the simulation.\n        area_size_variance (float): Variance in area sizes to introduce\n            non-uniformity among election territories.\n        common_assets (int): Total resources to be distributed among all agents.\n        av_area_color_dst (ndarray): Current (area)-average color distribution.\n        election_costs (float): Cost associated with participating in elections.\n        max_reward (float): Maximum reward possible for an agent each election.\n        known_cells (int): Number of cells each agent knows the color of.\n        datacollector (mesa.DataCollector): A tool for collecting data\n            (metrics and statistics) at each simulation step.\n        scheduler (CustomScheduler): The scheduler responsible for executing the\n            step function.\n        draw_borders (bool): Only for visualization (no effect on simulation).\n        _preset_color_dst (ndarray): A predefined global color distribution\n            (set randomly) that affects cell initialization globally.\n        \"\"\"\n\n    def __init__(self, height, width, num_agents, num_colors, num_personalities,\n                 mu, election_impact_on_mutation, common_assets, known_cells,\n                 num_areas, av_area_height, av_area_width, area_size_variance,\n                 patch_power, color_patches_steps, draw_borders, heterogeneity,\n                 rule_idx, distance_idx, election_costs, max_reward,\n                 show_area_stats):\n        super().__init__()\n        # TODO clean up class (public/private variables)\n        self.height = height\n        self.width = width\n        self.colors = np.arange(num_colors)\n        # Create a scheduler that goes through areas first then color cells\n        self.scheduler = CustomScheduler(self)\n        # The grid\n        # SingleGrid enforces at most one agent per cell;\n        # MultiGrid allows multiple agents to be in the same cell.\n        self.grid = mesa.space.SingleGrid(height=height, width=width, torus=True)\n        # Random bias factors that affect the initial color distribution\n        self._vertical_bias = self.random.uniform(0, 1)\n        self._horizontal_bias = self.random.uniform(0, 1)\n        self.draw_borders = draw_borders\n        # Color distribution (global)\n        self._preset_color_dst = self.create_color_distribution(heterogeneity)\n        self._av_area_color_dst = self._preset_color_dst\n        # Elections\n        self.election_costs = election_costs\n        self.max_reward = max_reward\n        self.known_cells = known_cells  # Integer\n        self.voting_rule = social_welfare_functions[rule_idx]\n        self.distance_func = distance_functions[distance_idx]\n        self.options = self.create_all_options(num_colors)\n        # Simulation variables\n        self.mu = mu  # Mutation rate for the color cells (0.1 = 10 % mutate)\n        self.common_assets = common_assets\n        # Election impact factor on color mutation through a probability array\n        self.color_probs = self.init_color_probs(election_impact_on_mutation)\n        # Create search pairs once for faster iterations when comparing rankings\n        self.search_pairs = list(combinations(range(0, self.options.size), 2))  # TODO check if correct!\n        self.option_vec = np.arange(self.options.size)  # Also to speed up\n        self.color_search_pairs = list(combinations(range(0, num_colors), 2))\n        # Create color cells\n        self.color_cells: List[Optional[ColorCell]] = [None] * (height * width)\n        self._initialize_color_cells()\n        # Create agents\n        # TODO: Where do the agents get there known cells from and how!?\n        self.voting_agents: List[Optional[VoteAgent]] = [None] * num_agents\n        self.personalities = self.create_personalities(num_personalities)\n        self.personality_distribution = self.pers_dist(num_personalities)\n        self.initialize_voting_agents()\n        # Area variables\n        self.global_area = self.initialize_global_area()  # TODO create bool variable to make this optional\n        self.areas: List[Optional[Area]] = [None] * num_areas\n        self.av_area_height = av_area_height\n        self.av_area_width = av_area_width\n        self.area_size_variance = area_size_variance\n        # Adjust the color pattern to make it less random (see color patches)\n        self.adjust_color_pattern(color_patches_steps, patch_power)\n        # Create areas\n        self.initialize_all_areas()\n        # Data collector\n        self.datacollector = self.initialize_datacollector()\n        # Collect initial data\n        self.datacollector.collect(self)\n        # Statistics\n        self.show_area_stats = show_area_stats\n\n    @property\n    def num_colors(self):\n        return len(self.colors)\n\n    @property\n    def av_area_color_dst(self):\n        return self._av_area_color_dst\n\n    @av_area_color_dst.setter\n    def av_area_color_dst(self, value):\n        self._av_area_color_dst = value\n\n    @property\n    def num_agents(self):\n        return len(self.voting_agents)\n\n    @property\n    def num_areas(self):\n        return len(self.areas)\n\n    @property\n    def preset_color_dst(self):\n        return len(self._preset_color_dst)\n\n    def _initialize_color_cells(self):\n        \"\"\"\n        This method initializes a color cells for each cell in the model's grid.\n        \"\"\"\n        # Create a color cell for each cell in the grid\n        for unique_id, (_, (row, col)) in enumerate(self.grid.coord_iter()):\n            # The colors are chosen by a predefined color distribution\n            color = self.color_by_dst(self._preset_color_dst)\n            # Create the cell\n            cell = ColorCell(unique_id, self, (row, col), color)\n            # Add it to the grid\n            self.grid.place_agent(cell, (row, col))\n            # Add the color cell to the scheduler\n            #self.scheduler.add(cell) # TODO: check speed diffs using this..\n            # And to the 'model.color_cells' list (for faster access)\n            self.color_cells[unique_id] = cell  # TODO: check if its not better to simply use the grid when finally changing the grid type to SingleGrid\n\n    def initialize_voting_agents(self):\n        \"\"\"\n        This method initializes as many voting agents as set in the model with\n        a randomly chosen personality. It places them randomly on the grid.\n        It also ensures that each agent is assigned to the color cell it is\n        standing on.\n        \"\"\"\n        dist = self.personality_distribution\n        rng = np.random.default_rng()\n        assets = self.common_assets // self.num_agents\n        for a_id in range(self.num_agents):\n            # Get a random position\n            x = self.random.randrange(self.width)\n            y = self.random.randrange(self.height)\n            personality = rng.choice(self.personalities, p=dist)\n            # Create agent without appending (add to the pre-defined list)\n            agent = VoteAgent(a_id, self, (x, y), personality,\n                              assets=assets, add=False)  # TODO: initial assets?!\n            self.voting_agents[a_id] = agent  # Add using the index (faster)\n            # Add the agent to the grid by placing it on a cell\n            cell = self.grid.get_cell_list_contents([(x, y)])[0]\n            if TYPE_CHECKING:\n                cell = cast(ColorCell, cell)\n            cell.add_agent(agent)\n\n    def init_color_probs(self, election_impact):\n        \"\"\"\n        This method initializes a probability array for the mutation of colors.\n        The probabilities reflect the election outcome with some impact factor.\n\n        Args:\n            election_impact (float): The impact the election has on the mutation.\n        \"\"\"\n        p = (np.arange(self.num_colors, 0, -1)) ** election_impact\n        # Normalize\n        p = p / sum(p)\n        return p\n\n    def initialize_area(self, a_id: int, x_coord, y_coord):\n        \"\"\"\n        This method initializes one area in the models' grid.\n        \"\"\"\n        area = Area(a_id, self, self.av_area_height, self.av_area_width,\n                    self.area_size_variance)\n        # Place the area in the grid using its indexing field\n        # this adds the corresponding color cells and voting agents to the area\n        area.idx_field = (x_coord, y_coord)\n        # Save in the models' areas-list\n        self.areas[a_id] = area\n\n    def initialize_all_areas(self) -&gt; None:\n        \"\"\"\n        Initializes all areas on the grid in the model.\n\n        This method divides the grid into approximately evenly distributed areas,\n        ensuring that the areas are spaced as uniformly as possible based\n        on the grid dimensions and the average area size specified by\n        `av_area_width` and `av_area_height`.\n\n        The grid may contain more or fewer areas than an exact square\n        grid arrangement due to `num_areas` not always being a perfect square.\n        If the number of areas is not a perfect square, the remaining areas\n        are placed randomly on the grid to ensure that `num_areas`\n        areas are initialized.\n\n        Args:\n            None.\n\n        Returns:\n            None. initializes `num_areas` and places them directly on the grid.\n\n        Raises:\n            None, but if `self.num_areas == 0`, the method exits early.\n\n        Example:\n            - Given `num_areas = 4` and `grid.width = grid.height = 10`,\n              this method might initialize areas with approximate distances\n              to maximize uniform distribution (like a 2x2 grid).\n            - For `num_areas = 5`, four areas will be initialized evenly, and\n              the fifth will be placed randomly due to the uneven distribution.\n        \"\"\"\n        if self.num_areas == 0:\n            return\n        # Calculate the number of areas in each direction\n        roo_apx = round(sqrt(self.num_areas))\n        nr_areas_x = self.grid.width // self.av_area_width\n        nr_areas_y = self.grid.width // self.av_area_height\n        # Calculate the distance between the areas\n        area_x_dist = self.grid.width // roo_apx\n        area_y_dist = self.grid.height // roo_apx\n        print(f\"roo_apx: {roo_apx}, nr_areas_x: {nr_areas_x}, \"\n              f\"nr_areas_y: {nr_areas_y}, area_x_dist: {area_x_dist}, \"\n              f\"area_y_dist: {area_y_dist}\")  # TODO rm print\n        x_coords = range(0, self.grid.width, area_x_dist)\n        y_coords = range(0, self.grid.height, area_y_dist)\n        # Add additional areas if necessary (num_areas not a square number)\n        additional_x, additional_y = [], []\n        missing = self.num_areas - len(x_coords) * len(y_coords)\n        for _ in range(missing):\n            additional_x.append(self.random.randrange(self.grid.width))\n            additional_y.append(self.random.randrange(self.grid.height))\n        # Create the area's ids\n        a_ids = iter(range(self.num_areas))\n        # Initialize all areas\n        for x_coord in x_coords:\n            for y_coord in y_coords:\n                a_id = next(a_ids, -1)\n                if a_id == -1:\n                    break\n                self.initialize_area(a_id, x_coord, y_coord)\n        for x_coord, y_coord in zip(additional_x, additional_y):\n            self.initialize_area(next(a_ids), x_coord, y_coord)\n\n\n    def initialize_global_area(self):\n        \"\"\"\n        This method initializes the global area spanning the whole grid.\n\n        Returns:\n            Area: The global area (with unique_id set to -1 and idx to (0, 0)).\n        \"\"\"\n        global_area = Area(-1, self, self.height, self.width, 0)\n        # Place the area in the grid using its indexing field\n        # this adds the corresponding color cells and voting agents to the area\n        global_area.idx_field = (0, 0)\n        return global_area\n\n\n    def create_personalities(self, n: int):\n        \"\"\"\n        Creates n unique \"personalities,\" where a \"personality\" is a specific\n        permutation of self.num_colors color indices.\n\n        Args:\n            n (int): Number of unique personalities to generate.\n\n        Returns:\n            np.ndarray: Array of shape `(n, num_colors)`.\n\n        Raises:\n            ValueError: If `n` exceeds the possible unique permutations.\n\n        Example:\n            for n=2 and self.num_colors=3, the function could return:\n\n            [[1, 0, 2],\n            [2, 1, 0]]\n        \"\"\"\n        # p_colors = range(1, self.num_colors)  # Personalities exclude white\n        max_permutations = np.math.factorial(self.num_colors)\n        if n &gt; max_permutations or n &lt; 1:\n            raise ValueError(f\"Cannot generate {n} unique personalities: \"\n                             f\"only {max_permutations} unique ones exist.\")\n        selected_permutations = set()\n        while len(selected_permutations) &lt; n:\n            # Sample a permutation lazily and add it to the set\n            perm = tuple(self.random.sample(range(self.num_colors),\n                                            self.num_colors))\n            selected_permutations.add(perm)\n\n        return np.array(list(selected_permutations))\n\n\n    def initialize_datacollector(self):\n        color_data = {f\"Color {i}\": get_color_distribution_function(i) for i in\n                      range(self.num_colors)}\n        return mesa.DataCollector(\n            model_reporters={\n                \"Collective assets\": compute_collective_assets,\n                \"Gini Index (0-100)\": compute_gini_index,\n                \"Voter turnout globally (in percent)\": get_voter_turnout,\n                **color_data\n            },\n            agent_reporters={\n                # \"Voter Turnout\": lambda a: a.voter_turnout if isinstance(a, Area) else None,\n                # \"Color Distribution\": lambda a: a.color_distribution if isinstance(a, Area) else None,\n                #\n                #\"VoterTurnout\": lambda a: a.voter_turnout if isinstance(a, Area) else None,\n                \"VoterTurnout\": get_area_voter_turnout,\n                \"DistToReality\": get_area_dist_to_reality,\n                \"ColorDistribution\": get_area_color_distribution,\n                \"ElectionResults\": get_election_results,\n                # \"Personality-Based Reward\": get_area_personality_based_reward,\n                # \"Gini Index\": get_area_gini_index\n            },\n            # tables={\n            #    \"AreaData\": [\"Step\", \"AreaID\", \"ColorDistribution\",\n            #                 \"VoterTurnout\"]\n            # }\n        )\n\n\n    def step(self):\n        \"\"\"\n        Advance the model by one step.\n        \"\"\"\n\n        # Conduct elections in the areas\n        # and then mutate the color cells according to election outcomes\n        self.scheduler.step()\n        # Update the global color distribution\n        self.update_av_area_color_dst()\n        # Collect data for monitoring and data analysis\n        self.datacollector.collect(self)\n\n\n    def adjust_color_pattern(self, color_patches_steps: int, patch_power: float):\n        \"\"\"Adjusting the color pattern to make it less predictable.\n\n        Args:\n            color_patches_steps: How often to run the color-patches step.\n            patch_power: The power of the patching (like a radius of impact).\n        \"\"\"\n        cells = self.color_cells\n        for _ in range(color_patches_steps):\n            print(f\"Color adjustment step {_}\")\n            self.random.shuffle(cells)\n            for cell in cells:\n                most_common_color = self.color_patches(cell, patch_power)\n                cell.color = most_common_color\n\n\n    def create_color_distribution(self, heterogeneity: float):\n        \"\"\"\n        This method is used to create a color distribution that has a bias\n        according to the given heterogeneity factor.\n\n        Args:\n            heterogeneity (float): Factor used as sigma in 'random.gauss'.\n        \"\"\"\n        colors = range(self.num_colors)\n        values = [abs(self.random.gauss(1, heterogeneity)) for _ in colors]\n        # Normalize (with float division)\n        total = sum(values)\n        dst_array = [value / total for value in values]\n        return dst_array\n\n\n    def color_patches(self, cell: ColorCell, patch_power: float):\n        \"\"\"\n        This method is used to create a less random initial color distribution\n        using a similar logic to the color patches model.\n        It uses a (normalized) bias coordinate to center the impact of the\n        color patches structures impact around.\n\n        Args:\n            cell: The cell that may change its color accordingly\n            patch_power: Like a radius of impact around the bias point.\n\n        Returns:\n            int: The consensus color or the cell's own color if no consensus.\n        \"\"\"\n        # Calculate the normalized position of the cell\n        normalized_x = cell.row / self.height\n        normalized_y = cell.col / self.width\n        # Calculate the distance of the cell to the bias point\n        bias_factor = (abs(normalized_x - self._horizontal_bias)\n                       + abs(normalized_y - self._vertical_bias))\n        # The closer the cell to the bias-point, the less often it is\n        # to be replaced by a color chosen from the initial distribution:\n        if abs(self.random.gauss(0, patch_power)) &lt; bias_factor:\n            return self.color_by_dst(self._preset_color_dst)\n        # Otherwise, apply the color patches logic\n        neighbor_cells = self.grid.get_neighbors((cell.row, cell.col),\n                                                 moore=True,\n                                                 include_center=False)\n        color_counts = {}  # Count neighbors' colors\n        for neighbor in neighbor_cells:\n            if isinstance(neighbor, ColorCell):\n                color = neighbor.color\n                color_counts[color] = color_counts.get(color, 0) + 1\n        if color_counts:\n            max_count = max(color_counts.values())\n            most_common_colors = [color for color, count in color_counts.items()\n                                  if count == max_count]\n            return self.random.choice(most_common_colors)\n        return cell.color  # Return the cell's own color if no consensus\n\n\n    def update_av_area_color_dst(self):\n        \"\"\"\n        This method updates the av_area_color_dst attribute of the model.\n        Beware: On overlapping areas, cells are counted several times.\n        \"\"\"\n        sums = np.zeros(self.num_colors)\n        for area in self.areas:\n            sums += area.color_distribution\n        # Return the average color distributions\n        self.av_area_color_dst = sums / self.num_areas\n\n\n    @staticmethod\n    def pers_dist(size):\n        \"\"\"\n        This method creates a normalized normal distribution array for picking\n        and depicting the distribution of personalities in the model.\n\n        Args:\n            size: The mean value of the normal distribution.\n\n        Returns:\n            np.array: Normalized (sum is one) array mimicking a gaussian curve.\n        \"\"\"\n        # Generate a normal distribution\n        rng = np.random.default_rng()\n        dist = rng.normal(0, 1, size)\n        dist.sort()  # To create a gaussian curve like array\n        dist = np.abs(dist)  # Flip negative values \"up\"\n        # Normalize the distribution to sum to one\n        dist /= dist.sum()\n        return dist\n\n\n    @staticmethod\n    def create_all_options(n: int, include_ties=False):\n        \"\"\"\n        Creates a matrix (an array of all possible ranking vectors),\n        if specified including ties.\n        Rank values start from 0.\n\n        Args:\n            n (int): The number of items to rank (number of colors in our case)\n            include_ties (bool): If True, rankings include ties.\n\n        Returns:\n            np.array: A matrix containing all possible ranking vectors.\n        \"\"\"\n        if include_ties:\n            # Create all possible combinations and sort out invalid rankings\n            # i.e. [1, 1, 1] or [1, 2, 2] aren't valid as no option is ranked first.\n            r = np.array([np.array(comb) for comb in product(range(n), repeat=n)\n                          if set(range(max(comb))).issubset(comb)])\n        else:\n            r = np.array([np.array(p) for p in permutations(range(n))])\n        return r\n\n    @staticmethod\n    def color_by_dst(color_distribution: np.array) -&gt; int:\n        \"\"\"\n        Selects a color (int) from range(len(color_distribution))\n        based on the given color_distribution array, where each entry represents\n        the probability of selecting that index.\n\n        Args:\n            color_distribution: Array determining the selection probabilities.\n\n        Returns:\n            int: The selected index based on the given probabilities.\n\n        Example:\n            color_distribution = [0.2, 0.3, 0.5]\n            Color 1 will be selected with a probability of 0.3.\n        \"\"\"\n        if abs(sum(color_distribution) -1) &gt; 1e-8:\n            raise ValueError(\"The color_distribution array must sum to 1.\")\n        r = np.random.random()  # Random float between 0 and 1\n        cumulative_sum = 0.0\n        for color_idx, prob in enumerate(color_distribution):\n            if prob &lt; 0:\n                raise ValueError(\"color_distribution contains negative value.\")\n            cumulative_sum += prob\n            if r &lt; cumulative_sum:  # Compare r against the cumulative probability\n                return color_idx\n\n        # This point should never be reached.\n        raise ValueError(\"Unexpected error in color_distribution.\")\n</code></pre>"},{"location":"technical/api/Model/#democracy_sim.participation_model.ParticipationModel.adjust_color_pattern","title":"<code>adjust_color_pattern(color_patches_steps, patch_power)</code>","text":"<p>Adjusting the color pattern to make it less predictable.</p> <p>Parameters:</p> Name Type Description Default <code>color_patches_steps</code> <code>int</code> <p>How often to run the color-patches step.</p> required <code>patch_power</code> <code>float</code> <p>The power of the patching (like a radius of impact).</p> required Source code in <code>democracy_sim/participation_model.py</code> <pre><code>def adjust_color_pattern(self, color_patches_steps: int, patch_power: float):\n    \"\"\"Adjusting the color pattern to make it less predictable.\n\n    Args:\n        color_patches_steps: How often to run the color-patches step.\n        patch_power: The power of the patching (like a radius of impact).\n    \"\"\"\n    cells = self.color_cells\n    for _ in range(color_patches_steps):\n        print(f\"Color adjustment step {_}\")\n        self.random.shuffle(cells)\n        for cell in cells:\n            most_common_color = self.color_patches(cell, patch_power)\n            cell.color = most_common_color\n</code></pre>"},{"location":"technical/api/Model/#democracy_sim.participation_model.ParticipationModel.color_by_dst","title":"<code>color_by_dst(color_distribution)</code>  <code>staticmethod</code>","text":"<p>Selects a color (int) from range(len(color_distribution)) based on the given color_distribution array, where each entry represents the probability of selecting that index.</p> <p>Parameters:</p> Name Type Description Default <code>color_distribution</code> <code>array</code> <p>Array determining the selection probabilities.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The selected index based on the given probabilities.</p> Example <p>color_distribution = [0.2, 0.3, 0.5] Color 1 will be selected with a probability of 0.3.</p> Source code in <code>democracy_sim/participation_model.py</code> <pre><code>@staticmethod\ndef color_by_dst(color_distribution: np.array) -&gt; int:\n    \"\"\"\n    Selects a color (int) from range(len(color_distribution))\n    based on the given color_distribution array, where each entry represents\n    the probability of selecting that index.\n\n    Args:\n        color_distribution: Array determining the selection probabilities.\n\n    Returns:\n        int: The selected index based on the given probabilities.\n\n    Example:\n        color_distribution = [0.2, 0.3, 0.5]\n        Color 1 will be selected with a probability of 0.3.\n    \"\"\"\n    if abs(sum(color_distribution) -1) &gt; 1e-8:\n        raise ValueError(\"The color_distribution array must sum to 1.\")\n    r = np.random.random()  # Random float between 0 and 1\n    cumulative_sum = 0.0\n    for color_idx, prob in enumerate(color_distribution):\n        if prob &lt; 0:\n            raise ValueError(\"color_distribution contains negative value.\")\n        cumulative_sum += prob\n        if r &lt; cumulative_sum:  # Compare r against the cumulative probability\n            return color_idx\n\n    # This point should never be reached.\n    raise ValueError(\"Unexpected error in color_distribution.\")\n</code></pre>"},{"location":"technical/api/Model/#democracy_sim.participation_model.ParticipationModel.color_patches","title":"<code>color_patches(cell, patch_power)</code>","text":"<p>This method is used to create a less random initial color distribution using a similar logic to the color patches model. It uses a (normalized) bias coordinate to center the impact of the color patches structures impact around.</p> <p>Parameters:</p> Name Type Description Default <code>cell</code> <code>ColorCell</code> <p>The cell that may change its color accordingly</p> required <code>patch_power</code> <code>float</code> <p>Like a radius of impact around the bias point.</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>The consensus color or the cell's own color if no consensus.</p> Source code in <code>democracy_sim/participation_model.py</code> <pre><code>def color_patches(self, cell: ColorCell, patch_power: float):\n    \"\"\"\n    This method is used to create a less random initial color distribution\n    using a similar logic to the color patches model.\n    It uses a (normalized) bias coordinate to center the impact of the\n    color patches structures impact around.\n\n    Args:\n        cell: The cell that may change its color accordingly\n        patch_power: Like a radius of impact around the bias point.\n\n    Returns:\n        int: The consensus color or the cell's own color if no consensus.\n    \"\"\"\n    # Calculate the normalized position of the cell\n    normalized_x = cell.row / self.height\n    normalized_y = cell.col / self.width\n    # Calculate the distance of the cell to the bias point\n    bias_factor = (abs(normalized_x - self._horizontal_bias)\n                   + abs(normalized_y - self._vertical_bias))\n    # The closer the cell to the bias-point, the less often it is\n    # to be replaced by a color chosen from the initial distribution:\n    if abs(self.random.gauss(0, patch_power)) &lt; bias_factor:\n        return self.color_by_dst(self._preset_color_dst)\n    # Otherwise, apply the color patches logic\n    neighbor_cells = self.grid.get_neighbors((cell.row, cell.col),\n                                             moore=True,\n                                             include_center=False)\n    color_counts = {}  # Count neighbors' colors\n    for neighbor in neighbor_cells:\n        if isinstance(neighbor, ColorCell):\n            color = neighbor.color\n            color_counts[color] = color_counts.get(color, 0) + 1\n    if color_counts:\n        max_count = max(color_counts.values())\n        most_common_colors = [color for color, count in color_counts.items()\n                              if count == max_count]\n        return self.random.choice(most_common_colors)\n    return cell.color  # Return the cell's own color if no consensus\n</code></pre>"},{"location":"technical/api/Model/#democracy_sim.participation_model.ParticipationModel.create_all_options","title":"<code>create_all_options(n, include_ties=False)</code>  <code>staticmethod</code>","text":"<p>Creates a matrix (an array of all possible ranking vectors), if specified including ties. Rank values start from 0.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>The number of items to rank (number of colors in our case)</p> required <code>include_ties</code> <code>bool</code> <p>If True, rankings include ties.</p> <code>False</code> <p>Returns:</p> Type Description <p>np.array: A matrix containing all possible ranking vectors.</p> Source code in <code>democracy_sim/participation_model.py</code> <pre><code>@staticmethod\ndef create_all_options(n: int, include_ties=False):\n    \"\"\"\n    Creates a matrix (an array of all possible ranking vectors),\n    if specified including ties.\n    Rank values start from 0.\n\n    Args:\n        n (int): The number of items to rank (number of colors in our case)\n        include_ties (bool): If True, rankings include ties.\n\n    Returns:\n        np.array: A matrix containing all possible ranking vectors.\n    \"\"\"\n    if include_ties:\n        # Create all possible combinations and sort out invalid rankings\n        # i.e. [1, 1, 1] or [1, 2, 2] aren't valid as no option is ranked first.\n        r = np.array([np.array(comb) for comb in product(range(n), repeat=n)\n                      if set(range(max(comb))).issubset(comb)])\n    else:\n        r = np.array([np.array(p) for p in permutations(range(n))])\n    return r\n</code></pre>"},{"location":"technical/api/Model/#democracy_sim.participation_model.ParticipationModel.create_color_distribution","title":"<code>create_color_distribution(heterogeneity)</code>","text":"<p>This method is used to create a color distribution that has a bias according to the given heterogeneity factor.</p> <p>Parameters:</p> Name Type Description Default <code>heterogeneity</code> <code>float</code> <p>Factor used as sigma in 'random.gauss'.</p> required Source code in <code>democracy_sim/participation_model.py</code> <pre><code>def create_color_distribution(self, heterogeneity: float):\n    \"\"\"\n    This method is used to create a color distribution that has a bias\n    according to the given heterogeneity factor.\n\n    Args:\n        heterogeneity (float): Factor used as sigma in 'random.gauss'.\n    \"\"\"\n    colors = range(self.num_colors)\n    values = [abs(self.random.gauss(1, heterogeneity)) for _ in colors]\n    # Normalize (with float division)\n    total = sum(values)\n    dst_array = [value / total for value in values]\n    return dst_array\n</code></pre>"},{"location":"technical/api/Model/#democracy_sim.participation_model.ParticipationModel.create_personalities","title":"<code>create_personalities(n)</code>","text":"<p>Creates n unique \"personalities,\" where a \"personality\" is a specific permutation of self.num_colors color indices.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of unique personalities to generate.</p> required <p>Returns:</p> Type Description <p>np.ndarray: Array of shape <code>(n, num_colors)</code>.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>n</code> exceeds the possible unique permutations.</p> Example <p>for n=2 and self.num_colors=3, the function could return:</p> <p>[[1, 0, 2], [2, 1, 0]]</p> Source code in <code>democracy_sim/participation_model.py</code> <pre><code>def create_personalities(self, n: int):\n    \"\"\"\n    Creates n unique \"personalities,\" where a \"personality\" is a specific\n    permutation of self.num_colors color indices.\n\n    Args:\n        n (int): Number of unique personalities to generate.\n\n    Returns:\n        np.ndarray: Array of shape `(n, num_colors)`.\n\n    Raises:\n        ValueError: If `n` exceeds the possible unique permutations.\n\n    Example:\n        for n=2 and self.num_colors=3, the function could return:\n\n        [[1, 0, 2],\n        [2, 1, 0]]\n    \"\"\"\n    # p_colors = range(1, self.num_colors)  # Personalities exclude white\n    max_permutations = np.math.factorial(self.num_colors)\n    if n &gt; max_permutations or n &lt; 1:\n        raise ValueError(f\"Cannot generate {n} unique personalities: \"\n                         f\"only {max_permutations} unique ones exist.\")\n    selected_permutations = set()\n    while len(selected_permutations) &lt; n:\n        # Sample a permutation lazily and add it to the set\n        perm = tuple(self.random.sample(range(self.num_colors),\n                                        self.num_colors))\n        selected_permutations.add(perm)\n\n    return np.array(list(selected_permutations))\n</code></pre>"},{"location":"technical/api/Model/#democracy_sim.participation_model.ParticipationModel.init_color_probs","title":"<code>init_color_probs(election_impact)</code>","text":"<p>This method initializes a probability array for the mutation of colors. The probabilities reflect the election outcome with some impact factor.</p> <p>Parameters:</p> Name Type Description Default <code>election_impact</code> <code>float</code> <p>The impact the election has on the mutation.</p> required Source code in <code>democracy_sim/participation_model.py</code> <pre><code>def init_color_probs(self, election_impact):\n    \"\"\"\n    This method initializes a probability array for the mutation of colors.\n    The probabilities reflect the election outcome with some impact factor.\n\n    Args:\n        election_impact (float): The impact the election has on the mutation.\n    \"\"\"\n    p = (np.arange(self.num_colors, 0, -1)) ** election_impact\n    # Normalize\n    p = p / sum(p)\n    return p\n</code></pre>"},{"location":"technical/api/Model/#democracy_sim.participation_model.ParticipationModel.initialize_all_areas","title":"<code>initialize_all_areas()</code>","text":"<p>Initializes all areas on the grid in the model.</p> <p>This method divides the grid into approximately evenly distributed areas, ensuring that the areas are spaced as uniformly as possible based on the grid dimensions and the average area size specified by <code>av_area_width</code> and <code>av_area_height</code>.</p> <p>The grid may contain more or fewer areas than an exact square grid arrangement due to <code>num_areas</code> not always being a perfect square. If the number of areas is not a perfect square, the remaining areas are placed randomly on the grid to ensure that <code>num_areas</code> areas are initialized.</p> <p>Returns:</p> Type Description <code>None</code> <p>None. initializes <code>num_areas</code> and places them directly on the grid.</p> Example <ul> <li>Given <code>num_areas = 4</code> and <code>grid.width = grid.height = 10</code>,   this method might initialize areas with approximate distances   to maximize uniform distribution (like a 2x2 grid).</li> <li>For <code>num_areas = 5</code>, four areas will be initialized evenly, and   the fifth will be placed randomly due to the uneven distribution.</li> </ul> Source code in <code>democracy_sim/participation_model.py</code> <pre><code>def initialize_all_areas(self) -&gt; None:\n    \"\"\"\n    Initializes all areas on the grid in the model.\n\n    This method divides the grid into approximately evenly distributed areas,\n    ensuring that the areas are spaced as uniformly as possible based\n    on the grid dimensions and the average area size specified by\n    `av_area_width` and `av_area_height`.\n\n    The grid may contain more or fewer areas than an exact square\n    grid arrangement due to `num_areas` not always being a perfect square.\n    If the number of areas is not a perfect square, the remaining areas\n    are placed randomly on the grid to ensure that `num_areas`\n    areas are initialized.\n\n    Args:\n        None.\n\n    Returns:\n        None. initializes `num_areas` and places them directly on the grid.\n\n    Raises:\n        None, but if `self.num_areas == 0`, the method exits early.\n\n    Example:\n        - Given `num_areas = 4` and `grid.width = grid.height = 10`,\n          this method might initialize areas with approximate distances\n          to maximize uniform distribution (like a 2x2 grid).\n        - For `num_areas = 5`, four areas will be initialized evenly, and\n          the fifth will be placed randomly due to the uneven distribution.\n    \"\"\"\n    if self.num_areas == 0:\n        return\n    # Calculate the number of areas in each direction\n    roo_apx = round(sqrt(self.num_areas))\n    nr_areas_x = self.grid.width // self.av_area_width\n    nr_areas_y = self.grid.width // self.av_area_height\n    # Calculate the distance between the areas\n    area_x_dist = self.grid.width // roo_apx\n    area_y_dist = self.grid.height // roo_apx\n    print(f\"roo_apx: {roo_apx}, nr_areas_x: {nr_areas_x}, \"\n          f\"nr_areas_y: {nr_areas_y}, area_x_dist: {area_x_dist}, \"\n          f\"area_y_dist: {area_y_dist}\")  # TODO rm print\n    x_coords = range(0, self.grid.width, area_x_dist)\n    y_coords = range(0, self.grid.height, area_y_dist)\n    # Add additional areas if necessary (num_areas not a square number)\n    additional_x, additional_y = [], []\n    missing = self.num_areas - len(x_coords) * len(y_coords)\n    for _ in range(missing):\n        additional_x.append(self.random.randrange(self.grid.width))\n        additional_y.append(self.random.randrange(self.grid.height))\n    # Create the area's ids\n    a_ids = iter(range(self.num_areas))\n    # Initialize all areas\n    for x_coord in x_coords:\n        for y_coord in y_coords:\n            a_id = next(a_ids, -1)\n            if a_id == -1:\n                break\n            self.initialize_area(a_id, x_coord, y_coord)\n    for x_coord, y_coord in zip(additional_x, additional_y):\n        self.initialize_area(next(a_ids), x_coord, y_coord)\n</code></pre>"},{"location":"technical/api/Model/#democracy_sim.participation_model.ParticipationModel.initialize_area","title":"<code>initialize_area(a_id, x_coord, y_coord)</code>","text":"<p>This method initializes one area in the models' grid.</p> Source code in <code>democracy_sim/participation_model.py</code> <pre><code>def initialize_area(self, a_id: int, x_coord, y_coord):\n    \"\"\"\n    This method initializes one area in the models' grid.\n    \"\"\"\n    area = Area(a_id, self, self.av_area_height, self.av_area_width,\n                self.area_size_variance)\n    # Place the area in the grid using its indexing field\n    # this adds the corresponding color cells and voting agents to the area\n    area.idx_field = (x_coord, y_coord)\n    # Save in the models' areas-list\n    self.areas[a_id] = area\n</code></pre>"},{"location":"technical/api/Model/#democracy_sim.participation_model.ParticipationModel.initialize_global_area","title":"<code>initialize_global_area()</code>","text":"<p>This method initializes the global area spanning the whole grid.</p> <p>Returns:</p> Name Type Description <code>Area</code> <p>The global area (with unique_id set to -1 and idx to (0, 0)).</p> Source code in <code>democracy_sim/participation_model.py</code> <pre><code>def initialize_global_area(self):\n    \"\"\"\n    This method initializes the global area spanning the whole grid.\n\n    Returns:\n        Area: The global area (with unique_id set to -1 and idx to (0, 0)).\n    \"\"\"\n    global_area = Area(-1, self, self.height, self.width, 0)\n    # Place the area in the grid using its indexing field\n    # this adds the corresponding color cells and voting agents to the area\n    global_area.idx_field = (0, 0)\n    return global_area\n</code></pre>"},{"location":"technical/api/Model/#democracy_sim.participation_model.ParticipationModel.initialize_voting_agents","title":"<code>initialize_voting_agents()</code>","text":"<p>This method initializes as many voting agents as set in the model with a randomly chosen personality. It places them randomly on the grid. It also ensures that each agent is assigned to the color cell it is standing on.</p> Source code in <code>democracy_sim/participation_model.py</code> <pre><code>def initialize_voting_agents(self):\n    \"\"\"\n    This method initializes as many voting agents as set in the model with\n    a randomly chosen personality. It places them randomly on the grid.\n    It also ensures that each agent is assigned to the color cell it is\n    standing on.\n    \"\"\"\n    dist = self.personality_distribution\n    rng = np.random.default_rng()\n    assets = self.common_assets // self.num_agents\n    for a_id in range(self.num_agents):\n        # Get a random position\n        x = self.random.randrange(self.width)\n        y = self.random.randrange(self.height)\n        personality = rng.choice(self.personalities, p=dist)\n        # Create agent without appending (add to the pre-defined list)\n        agent = VoteAgent(a_id, self, (x, y), personality,\n                          assets=assets, add=False)  # TODO: initial assets?!\n        self.voting_agents[a_id] = agent  # Add using the index (faster)\n        # Add the agent to the grid by placing it on a cell\n        cell = self.grid.get_cell_list_contents([(x, y)])[0]\n        if TYPE_CHECKING:\n            cell = cast(ColorCell, cell)\n        cell.add_agent(agent)\n</code></pre>"},{"location":"technical/api/Model/#democracy_sim.participation_model.ParticipationModel.pers_dist","title":"<code>pers_dist(size)</code>  <code>staticmethod</code>","text":"<p>This method creates a normalized normal distribution array for picking and depicting the distribution of personalities in the model.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <p>The mean value of the normal distribution.</p> required <p>Returns:</p> Type Description <p>np.array: Normalized (sum is one) array mimicking a gaussian curve.</p> Source code in <code>democracy_sim/participation_model.py</code> <pre><code>@staticmethod\ndef pers_dist(size):\n    \"\"\"\n    This method creates a normalized normal distribution array for picking\n    and depicting the distribution of personalities in the model.\n\n    Args:\n        size: The mean value of the normal distribution.\n\n    Returns:\n        np.array: Normalized (sum is one) array mimicking a gaussian curve.\n    \"\"\"\n    # Generate a normal distribution\n    rng = np.random.default_rng()\n    dist = rng.normal(0, 1, size)\n    dist.sort()  # To create a gaussian curve like array\n    dist = np.abs(dist)  # Flip negative values \"up\"\n    # Normalize the distribution to sum to one\n    dist /= dist.sum()\n    return dist\n</code></pre>"},{"location":"technical/api/Model/#democracy_sim.participation_model.ParticipationModel.step","title":"<code>step()</code>","text":"<p>Advance the model by one step.</p> Source code in <code>democracy_sim/participation_model.py</code> <pre><code>def step(self):\n    \"\"\"\n    Advance the model by one step.\n    \"\"\"\n\n    # Conduct elections in the areas\n    # and then mutate the color cells according to election outcomes\n    self.scheduler.step()\n    # Update the global color distribution\n    self.update_av_area_color_dst()\n    # Collect data for monitoring and data analysis\n    self.datacollector.collect(self)\n</code></pre>"},{"location":"technical/api/Model/#democracy_sim.participation_model.ParticipationModel.update_av_area_color_dst","title":"<code>update_av_area_color_dst()</code>","text":"<p>This method updates the av_area_color_dst attribute of the model. Beware: On overlapping areas, cells are counted several times.</p> Source code in <code>democracy_sim/participation_model.py</code> <pre><code>def update_av_area_color_dst(self):\n    \"\"\"\n    This method updates the av_area_color_dst attribute of the model.\n    Beware: On overlapping areas, cells are counted several times.\n    \"\"\"\n    sums = np.zeros(self.num_colors)\n    for area in self.areas:\n        sums += area.color_distribution\n    # Return the average color distributions\n    self.av_area_color_dst = sums / self.num_areas\n</code></pre>"},{"location":"technical/api/Utility_functions/","title":"Utility functions","text":"<p>Combine two arrays weighted by a factor favoring arr_1. The first array is to be the estimated real distribution. And the other is to be the personality vector of the agent.</p> <p>Parameters:</p> Name Type Description Default <code>arr_1</code> <code>array</code> <p>The first array to be combined (real distribution).</p> required <code>arr_2</code> <code>array</code> <p>The second array to be combined (personality vector).</p> required <code>factor</code> <code>float</code> <p>The factor to weigh the two arrays.</p> required <p>Returns:</p> Name Type Description <code>result</code> <code>array</code> <p>The normalized weighted linear combination.</p> Example <p>TODO</p> Source code in <code>democracy_sim/participation_agent.py</code> <pre><code>def combine_and_normalize(arr_1: np.array, arr_2: np.array, factor: float):\n    \"\"\"\n    Combine two arrays weighted by a factor favoring arr_1.\n    The first array is to be the estimated real distribution.\n    And the other is to be the personality vector of the agent.\n\n    Args:\n        arr_1: The first array to be combined (real distribution).\n        arr_2: The second array to be combined (personality vector).\n        factor: The factor to weigh the two arrays.\n\n    Returns:\n        result (np.array): The normalized weighted linear combination.\n\n    Example:\n        TODO\n    \"\"\"\n    # Ensure f is between 0 and 1 TODO: remove this on simulations to speed up\n    if not (0 &lt;= factor &lt;= 1):\n        raise ValueError(\"Factor f must be between 0 and 1\")\n    # Linear combination\n    res = factor * arr_1 + (1 - factor) * arr_2\n    # Normalize/scale result s. t. it resembles a distribution vector (sum=1)\n    total = sum(res)\n    # assert total == 1.0, f\"Sum of result is {total} and not 1.0\"\n    return res / total\n</code></pre>"},{"location":"technical/api/VoteAgent/","title":"Class <code>VoteAgent</code>","text":"<p>               Bases: <code>Agent</code></p> <p>An agent that has limited knowledge and resources and can decide to use them to participate in elections.</p> Source code in <code>democracy_sim/participation_agent.py</code> <pre><code>class VoteAgent(Agent):\n    \"\"\"An agent that has limited knowledge and resources and\n    can decide to use them to participate in elections.\n    \"\"\"\n\n    def __init__(self, unique_id, model, pos, personality, assets=1, add=True):\n        \"\"\" Create a new agent.\n\n        Attributes:\n            unique_id: The unique identifier of the agent.\n            model: The simulation model of which the agent is part of.\n            pos: The position of the agent in the grid.\n            personality: Represents the agent's preferences among colors.\n            assets: The wealth/assets/motivation of the agent.\n        \"\"\"\n        super().__init__(unique_id=unique_id, model=model)\n        # The \"pos\" variable in mesa is special, so I avoid it here\n        try:\n            row, col = pos\n        except ValueError:\n            raise ValueError(\"Position must be a tuple of two integers.\")\n        self._position = row, col\n        self._assets = assets\n        self._num_elections_participated = 0\n        self.personality = personality\n        self.cell = model.grid.get_cell_list_contents([(row, col)])[0]\n        # ColorCell objects the agent knows (knowledge)\n        self.known_cells: List[Optional[ColorCell]] = [None] * model.known_cells\n        # Add the agent to the models' agent list and the cell\n        if add:\n            model.voting_agents.append(self)\n            cell = model.grid.get_cell_list_contents([(row, col)])[0]\n            cell.add_agent(self)\n        # Election relevant variables\n        self.est_real_dist = np.zeros(self.model.num_colors)\n        self.confidence = 0.0\n\n    def __str__(self):\n        return (f\"Agent(id={self.unique_id}, pos={self.position}, \"\n                f\"personality={self.personality}, assets={self.assets})\")\n\n    @property\n    def position(self):\n        \"\"\"Return the location of the agent.\"\"\"\n        return self._position\n\n    @property\n    def row(self):\n        \"\"\"Return the row location of the agent.\"\"\"\n        return self._position[0]\n\n    @property\n    def col(self):\n        \"\"\"Return the col location of the agent.\"\"\"\n        return self._position[1]\n\n    @property\n    def assets(self):\n        \"\"\"Return the assets of this agent.\"\"\"\n        return self._assets\n\n    @assets.setter\n    def assets(self, value):\n        self._assets = value\n\n    @assets.deleter\n    def assets(self):\n        del self._assets\n\n    @property\n    def num_elections_participated(self):\n        return self._num_elections_participated\n\n    @num_elections_participated.setter\n    def num_elections_participated(self, value):\n        self._num_elections_participated = value\n\n    def update_known_cells(self, area):\n        \"\"\"\n        This method is to update the list of known cells before casting a vote.\n\n        Args:\n            area: The area that holds the pool of cells in question\n        \"\"\"\n        n_cells = len(area.cells)\n        k = len(self.known_cells)\n        self.known_cells = (\n            self.random.sample(area.cells, k)\n            if n_cells &gt;= k\n            else area.cells\n        )\n\n    def ask_for_participation(self, area):\n        \"\"\"\n        The agent decides\n        whether to participate in the upcoming election of a given area.\n\n        Args:\n            area: The area in which the election takes place.\n\n        Returns:\n            True if the agent decides to participate, False otherwise\n        \"\"\"\n        #print(\"Agent\", self.unique_id, \"decides whether to participate\",\n        #      \"in election of area\", area.unique_id)\n        # TODO Implement this (is to be decided upon a learned decision tree)\n        return np.random.choice([True, False])\n\n    def decide_altruism_factor(self, area):\n        \"\"\"\n        Uses a trained decision tree to decide on the altruism factor.\n        \"\"\"\n        # TODO Implement this (is to be decided upon a learned decision tree)\n        # This part is important - also for monitoring - save/plot a_factors\n        a_factor = np.random.uniform(0.0, 1.0)\n        #print(f\"Agent {self.unique_id} has an altruism factor of: {a_factor}\")\n        return a_factor\n\n    def compute_assumed_opt_dist(self, area):\n        \"\"\"\n        Computes a color distribution that the agent assumes to be an optimal\n        choice in any election (regardless of whether it exists as a real option\n        to vote for or not). It takes \"altruistic\" concepts into consideration.\n\n        Args:\n            area (Area): The area in which the election takes place.\n\n        Returns:\n            ass_opt: The assumed optimal color distribution (normalized).\n        \"\"\"\n        # Compute the \"altruism_factor\" via a decision tree\n        a_factor = self.decide_altruism_factor(area)  # TODO: Implement this\n        # Compute the preference ranking vector as a mix between the agent's own\n        #   preferences/personality traits and the estimated real distribution.\n        est_dist, conf = self.estimate_real_distribution(area)\n        ass_opt = combine_and_normalize(est_dist, self.personality, a_factor)\n        return ass_opt\n\n    def vote(self, area):\n        \"\"\"\n        The agent votes in the election of a given area,\n        i.e., she returns a preference ranking vector over all options.\n        (Ranking: `index = option`, `value proportional to rank`)\n        The available options are set in the model.\n\n        Args:\n            area (Area): The area in which the election takes place.\n        \"\"\"\n        # TODO Implement this (is to be decided upon a learned decision tree)\n        # Compute the color distribution that is assumed to be the best choice.\n        est_best_dist = self.compute_assumed_opt_dist(area)\n        # Make sure that r= is normalized!\n        # (r.min()=0.0 and r.max()=1.0 and all vals x are within [0.0, 1.0]!)\n        ##############\n        if TYPE_CHECKING:  # Type hint for IDEs\n            self.model = cast(ParticipationModel, self.model)\n\n        options = self.model.options\n        dist_func = self.model.distance_func\n        ranking = np.zeros(options.shape[0])\n        color_search_pairs = self.model.color_search_pairs\n        for i, option in enumerate(options):\n            # TODO: is it possible to leave out white?\n            ranking[i] = dist_func(self.personality, option, color_search_pairs)\n        ranking /= ranking.sum()  # Normalize the preference vector\n        return ranking\n\n    def estimate_real_distribution(self, area):\n        \"\"\"\n        The agent estimates the real color distribution in the area based on\n        her own knowledge (self.known_cells).\n\n        Args:\n            area (Area): The area the agent uses to estimate.\n        \"\"\"\n        known_colors = np.array([cell.color for cell in self.known_cells])\n        # Get the unique color ids present and count their occurrence\n        unique, counts = np.unique(known_colors, return_counts=True)\n        # Update the est_real_dist and confidence values of the agent\n        self.est_real_dist.fill(0)  # To ensure the ones not in unique are 0\n        self.est_real_dist[unique] = counts / known_colors.size\n        self.confidence = len(self.known_cells) / area.num_cells\n        return self.est_real_dist, self.confidence\n</code></pre>"},{"location":"technical/api/VoteAgent/#democracy_sim.participation_agent.VoteAgent.assets","title":"<code>assets</code>  <code>deletable</code> <code>property</code> <code>writable</code>","text":"<p>Return the assets of this agent.</p>"},{"location":"technical/api/VoteAgent/#democracy_sim.participation_agent.VoteAgent.col","title":"<code>col</code>  <code>property</code>","text":"<p>Return the col location of the agent.</p>"},{"location":"technical/api/VoteAgent/#democracy_sim.participation_agent.VoteAgent.position","title":"<code>position</code>  <code>property</code>","text":"<p>Return the location of the agent.</p>"},{"location":"technical/api/VoteAgent/#democracy_sim.participation_agent.VoteAgent.row","title":"<code>row</code>  <code>property</code>","text":"<p>Return the row location of the agent.</p>"},{"location":"technical/api/VoteAgent/#democracy_sim.participation_agent.VoteAgent.__init__","title":"<code>__init__(unique_id, model, pos, personality, assets=1, add=True)</code>","text":"<p>Create a new agent.</p> <p>Attributes:</p> Name Type Description <code>unique_id</code> <p>The unique identifier of the agent.</p> <code>model</code> <p>The simulation model of which the agent is part of.</p> <code>pos</code> <p>The position of the agent in the grid.</p> <code>personality</code> <p>Represents the agent's preferences among colors.</p> <code>assets</code> <p>The wealth/assets/motivation of the agent.</p> Source code in <code>democracy_sim/participation_agent.py</code> <pre><code>def __init__(self, unique_id, model, pos, personality, assets=1, add=True):\n    \"\"\" Create a new agent.\n\n    Attributes:\n        unique_id: The unique identifier of the agent.\n        model: The simulation model of which the agent is part of.\n        pos: The position of the agent in the grid.\n        personality: Represents the agent's preferences among colors.\n        assets: The wealth/assets/motivation of the agent.\n    \"\"\"\n    super().__init__(unique_id=unique_id, model=model)\n    # The \"pos\" variable in mesa is special, so I avoid it here\n    try:\n        row, col = pos\n    except ValueError:\n        raise ValueError(\"Position must be a tuple of two integers.\")\n    self._position = row, col\n    self._assets = assets\n    self._num_elections_participated = 0\n    self.personality = personality\n    self.cell = model.grid.get_cell_list_contents([(row, col)])[0]\n    # ColorCell objects the agent knows (knowledge)\n    self.known_cells: List[Optional[ColorCell]] = [None] * model.known_cells\n    # Add the agent to the models' agent list and the cell\n    if add:\n        model.voting_agents.append(self)\n        cell = model.grid.get_cell_list_contents([(row, col)])[0]\n        cell.add_agent(self)\n    # Election relevant variables\n    self.est_real_dist = np.zeros(self.model.num_colors)\n    self.confidence = 0.0\n</code></pre>"},{"location":"technical/api/VoteAgent/#democracy_sim.participation_agent.VoteAgent.ask_for_participation","title":"<code>ask_for_participation(area)</code>","text":"<p>The agent decides whether to participate in the upcoming election of a given area.</p> <p>Parameters:</p> Name Type Description Default <code>area</code> <p>The area in which the election takes place.</p> required <p>Returns:</p> Type Description <p>True if the agent decides to participate, False otherwise</p> Source code in <code>democracy_sim/participation_agent.py</code> <pre><code>def ask_for_participation(self, area):\n    \"\"\"\n    The agent decides\n    whether to participate in the upcoming election of a given area.\n\n    Args:\n        area: The area in which the election takes place.\n\n    Returns:\n        True if the agent decides to participate, False otherwise\n    \"\"\"\n    #print(\"Agent\", self.unique_id, \"decides whether to participate\",\n    #      \"in election of area\", area.unique_id)\n    # TODO Implement this (is to be decided upon a learned decision tree)\n    return np.random.choice([True, False])\n</code></pre>"},{"location":"technical/api/VoteAgent/#democracy_sim.participation_agent.VoteAgent.compute_assumed_opt_dist","title":"<code>compute_assumed_opt_dist(area)</code>","text":"<p>Computes a color distribution that the agent assumes to be an optimal choice in any election (regardless of whether it exists as a real option to vote for or not). It takes \"altruistic\" concepts into consideration.</p> <p>Parameters:</p> Name Type Description Default <code>area</code> <code>Area</code> <p>The area in which the election takes place.</p> required <p>Returns:</p> Name Type Description <code>ass_opt</code> <p>The assumed optimal color distribution (normalized).</p> Source code in <code>democracy_sim/participation_agent.py</code> <pre><code>def compute_assumed_opt_dist(self, area):\n    \"\"\"\n    Computes a color distribution that the agent assumes to be an optimal\n    choice in any election (regardless of whether it exists as a real option\n    to vote for or not). It takes \"altruistic\" concepts into consideration.\n\n    Args:\n        area (Area): The area in which the election takes place.\n\n    Returns:\n        ass_opt: The assumed optimal color distribution (normalized).\n    \"\"\"\n    # Compute the \"altruism_factor\" via a decision tree\n    a_factor = self.decide_altruism_factor(area)  # TODO: Implement this\n    # Compute the preference ranking vector as a mix between the agent's own\n    #   preferences/personality traits and the estimated real distribution.\n    est_dist, conf = self.estimate_real_distribution(area)\n    ass_opt = combine_and_normalize(est_dist, self.personality, a_factor)\n    return ass_opt\n</code></pre>"},{"location":"technical/api/VoteAgent/#democracy_sim.participation_agent.VoteAgent.decide_altruism_factor","title":"<code>decide_altruism_factor(area)</code>","text":"<p>Uses a trained decision tree to decide on the altruism factor.</p> Source code in <code>democracy_sim/participation_agent.py</code> <pre><code>def decide_altruism_factor(self, area):\n    \"\"\"\n    Uses a trained decision tree to decide on the altruism factor.\n    \"\"\"\n    # TODO Implement this (is to be decided upon a learned decision tree)\n    # This part is important - also for monitoring - save/plot a_factors\n    a_factor = np.random.uniform(0.0, 1.0)\n    #print(f\"Agent {self.unique_id} has an altruism factor of: {a_factor}\")\n    return a_factor\n</code></pre>"},{"location":"technical/api/VoteAgent/#democracy_sim.participation_agent.VoteAgent.estimate_real_distribution","title":"<code>estimate_real_distribution(area)</code>","text":"<p>The agent estimates the real color distribution in the area based on her own knowledge (self.known_cells).</p> <p>Parameters:</p> Name Type Description Default <code>area</code> <code>Area</code> <p>The area the agent uses to estimate.</p> required Source code in <code>democracy_sim/participation_agent.py</code> <pre><code>def estimate_real_distribution(self, area):\n    \"\"\"\n    The agent estimates the real color distribution in the area based on\n    her own knowledge (self.known_cells).\n\n    Args:\n        area (Area): The area the agent uses to estimate.\n    \"\"\"\n    known_colors = np.array([cell.color for cell in self.known_cells])\n    # Get the unique color ids present and count their occurrence\n    unique, counts = np.unique(known_colors, return_counts=True)\n    # Update the est_real_dist and confidence values of the agent\n    self.est_real_dist.fill(0)  # To ensure the ones not in unique are 0\n    self.est_real_dist[unique] = counts / known_colors.size\n    self.confidence = len(self.known_cells) / area.num_cells\n    return self.est_real_dist, self.confidence\n</code></pre>"},{"location":"technical/api/VoteAgent/#democracy_sim.participation_agent.VoteAgent.update_known_cells","title":"<code>update_known_cells(area)</code>","text":"<p>This method is to update the list of known cells before casting a vote.</p> <p>Parameters:</p> Name Type Description Default <code>area</code> <p>The area that holds the pool of cells in question</p> required Source code in <code>democracy_sim/participation_agent.py</code> <pre><code>def update_known_cells(self, area):\n    \"\"\"\n    This method is to update the list of known cells before casting a vote.\n\n    Args:\n        area: The area that holds the pool of cells in question\n    \"\"\"\n    n_cells = len(area.cells)\n    k = len(self.known_cells)\n    self.known_cells = (\n        self.random.sample(area.cells, k)\n        if n_cells &gt;= k\n        else area.cells\n    )\n</code></pre>"},{"location":"technical/api/VoteAgent/#democracy_sim.participation_agent.VoteAgent.vote","title":"<code>vote(area)</code>","text":"<p>The agent votes in the election of a given area, i.e., she returns a preference ranking vector over all options. (Ranking: <code>index = option</code>, <code>value proportional to rank</code>) The available options are set in the model.</p> <p>Parameters:</p> Name Type Description Default <code>area</code> <code>Area</code> <p>The area in which the election takes place.</p> required Source code in <code>democracy_sim/participation_agent.py</code> <pre><code>def vote(self, area):\n    \"\"\"\n    The agent votes in the election of a given area,\n    i.e., she returns a preference ranking vector over all options.\n    (Ranking: `index = option`, `value proportional to rank`)\n    The available options are set in the model.\n\n    Args:\n        area (Area): The area in which the election takes place.\n    \"\"\"\n    # TODO Implement this (is to be decided upon a learned decision tree)\n    # Compute the color distribution that is assumed to be the best choice.\n    est_best_dist = self.compute_assumed_opt_dist(area)\n    # Make sure that r= is normalized!\n    # (r.min()=0.0 and r.max()=1.0 and all vals x are within [0.0, 1.0]!)\n    ##############\n    if TYPE_CHECKING:  # Type hint for IDEs\n        self.model = cast(ParticipationModel, self.model)\n\n    options = self.model.options\n    dist_func = self.model.distance_func\n    ranking = np.zeros(options.shape[0])\n    color_search_pairs = self.model.color_search_pairs\n    for i, option in enumerate(options):\n        # TODO: is it possible to leave out white?\n        ranking[i] = dist_func(self.personality, option, color_search_pairs)\n    ranking /= ranking.sum()  # Normalize the preference vector\n    return ranking\n</code></pre>"},{"location":"technical/api/inherited/","title":"Inherited Classes","text":""},{"location":"technical/api/inherited/#mesa-base-model-class","title":"Mesa Base Model Class","text":"<p>Base class for models in the Mesa ABM library.</p> <p>This class serves as a foundational structure for creating agent-based models. It includes the basic attributes and methods necessary for initializing and running a simulation model.</p> <p>Attributes:</p> Name Type Description <code>running</code> <p>A boolean indicating if the model should continue running.</p> <code>schedule</code> <p>An object to manage the order and execution of agent steps.</p> <code>current_id</code> <p>A counter for assigning unique IDs to agents.</p> <code>agents_</code> <code>defaultdict[type, dict]</code> <p>A defaultdict mapping each agent type to a dict of its instances.      This private attribute is used internally to manage agents.</p> Properties <p>agents: An AgentSet containing all agents in the model, generated from the _agents attribute. agent_types: A list of different agent types present in the model.</p> <p>Methods:</p> Name Description <code>get_agents_of_type</code> <p>Returns an AgentSet of agents of the specified type.</p> <code>run_model</code> <p>Runs the model's simulation until a defined end condition is reached.</p> <code>step</code> <p>Executes a single step of the model's simulation process.</p> <code>next_id</code> <p>Generates and returns the next unique identifier for an agent.</p> <code>reset_randomizer</code> <p>Resets the model's random number generator with a new or existing seed.</p> <code>initialize_data_collector</code> <p>Sets up the data collector for the model, requiring an initialized scheduler and agents.</p> Source code in <code>mesa/model.py</code> <pre><code>class Model:\n    \"\"\"Base class for models in the Mesa ABM library.\n\n    This class serves as a foundational structure for creating agent-based models.\n    It includes the basic attributes and methods necessary for initializing and\n    running a simulation model.\n\n    Attributes:\n        running: A boolean indicating if the model should continue running.\n        schedule: An object to manage the order and execution of agent steps.\n        current_id: A counter for assigning unique IDs to agents.\n        agents_: A defaultdict mapping each agent type to a dict of its instances.\n                 This private attribute is used internally to manage agents.\n\n    Properties:\n        agents: An AgentSet containing all agents in the model, generated from the _agents attribute.\n        agent_types: A list of different agent types present in the model.\n\n    Methods:\n        get_agents_of_type: Returns an AgentSet of agents of the specified type.\n        run_model: Runs the model's simulation until a defined end condition is reached.\n        step: Executes a single step of the model's simulation process.\n        next_id: Generates and returns the next unique identifier for an agent.\n        reset_randomizer: Resets the model's random number generator with a new or existing seed.\n        initialize_data_collector: Sets up the data collector for the model, requiring an initialized scheduler and agents.\n    \"\"\"\n\n    def __new__(cls, *args: Any, **kwargs: Any) -&gt; Any:\n        \"\"\"Create a new model object and instantiate its RNG automatically.\"\"\"\n        obj = object.__new__(cls)\n        obj._seed = kwargs.get(\"seed\")\n        if obj._seed is None:\n            # We explicitly specify the seed here so that we know its value in\n            # advance.\n            obj._seed = random.random()\n        obj.random = random.Random(obj._seed)\n        # TODO: Remove these 2 lines just before Mesa 3.0\n        obj._steps = 0\n        obj._time = 0\n        return obj\n\n    def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Create a new model. Overload this method with the actual code to\n        start the model. Always start with super().__init__() to initialize the\n        model object properly.\n        \"\"\"\n\n        self.running = True\n        self.schedule = None\n        self.current_id = 0\n        self.agents_: defaultdict[type, dict] = defaultdict(dict)\n\n        self._steps: int = 0\n        self._time: TimeT = 0  # the model's clock\n\n    @property\n    def agents(self) -&gt; AgentSet:\n        \"\"\"Provides an AgentSet of all agents in the model, combining agents from all types.\"\"\"\n\n        if hasattr(self, \"_agents\"):\n            return self._agents\n        else:\n            all_agents = itertools.chain.from_iterable(self.agents_.values())\n            return AgentSet(all_agents, self)\n\n    @agents.setter\n    def agents(self, agents: Any) -&gt; None:\n        warnings.warn(\n            \"You are trying to set model.agents. In a next release, this attribute is used \"\n            \"by MESA itself so you cannot use it directly anymore.\"\n            \"Please adjust your code to use a different attribute name for custom agent storage\",\n            UserWarning,\n            stacklevel=2,\n        )\n\n        self._agents = agents\n\n    @property\n    def agent_types(self) -&gt; list[type]:\n        \"\"\"Return a list of different agent types.\"\"\"\n        return list(self.agents_.keys())\n\n    def get_agents_of_type(self, agenttype: type[Agent]) -&gt; AgentSet:\n        \"\"\"Retrieves an AgentSet containing all agents of the specified type.\"\"\"\n        return AgentSet(self.agents_[agenttype].keys(), self)\n\n    def run_model(self) -&gt; None:\n        \"\"\"Run the model until the end condition is reached. Overload as\n        needed.\n        \"\"\"\n        while self.running:\n            self.step()\n\n    def step(self) -&gt; None:\n        \"\"\"A single step. Fill in here.\"\"\"\n\n    def _advance_time(self, deltat: TimeT = 1):\n        \"\"\"Increment the model's steps counter and clock.\"\"\"\n        self._steps += 1\n        self._time += deltat\n\n    def next_id(self) -&gt; int:\n        \"\"\"Return the next unique ID for agents, increment current_id\"\"\"\n        self.current_id += 1\n        return self.current_id\n\n    def reset_randomizer(self, seed: int | None = None) -&gt; None:\n        \"\"\"Reset the model random number generator.\n\n        Args:\n            seed: A new seed for the RNG; if None, reset using the current seed\n        \"\"\"\n\n        if seed is None:\n            seed = self._seed\n        self.random.seed(seed)\n        self._seed = seed\n\n    def initialize_data_collector(\n        self,\n        model_reporters=None,\n        agent_reporters=None,\n        tables=None,\n    ) -&gt; None:\n        if not hasattr(self, \"schedule\") or self.schedule is None:\n            raise RuntimeError(\n                \"You must initialize the scheduler (self.schedule) before initializing the data collector.\"\n            )\n        if self.schedule.get_agent_count() == 0:\n            raise RuntimeError(\n                \"You must add agents to the scheduler before initializing the data collector.\"\n            )\n        self.datacollector = DataCollector(\n            model_reporters=model_reporters,\n            agent_reporters=agent_reporters,\n            tables=tables,\n        )\n        # Collect data for the first time during initialization.\n        self.datacollector.collect(self)\n</code></pre>"},{"location":"technical/api/inherited/#mesa.Model.agent_types","title":"<code>agent_types</code>  <code>property</code>","text":"<p>Return a list of different agent types.</p>"},{"location":"technical/api/inherited/#mesa.Model.agents","title":"<code>agents</code>  <code>property</code> <code>writable</code>","text":"<p>Provides an AgentSet of all agents in the model, combining agents from all types.</p>"},{"location":"technical/api/inherited/#mesa.Model.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Create a new model. Overload this method with the actual code to start the model. Always start with super().init() to initialize the model object properly.</p> Source code in <code>mesa/model.py</code> <pre><code>def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Create a new model. Overload this method with the actual code to\n    start the model. Always start with super().__init__() to initialize the\n    model object properly.\n    \"\"\"\n\n    self.running = True\n    self.schedule = None\n    self.current_id = 0\n    self.agents_: defaultdict[type, dict] = defaultdict(dict)\n\n    self._steps: int = 0\n    self._time: TimeT = 0  # the model's clock\n</code></pre>"},{"location":"technical/api/inherited/#mesa.Model.__new__","title":"<code>__new__(*args, **kwargs)</code>","text":"<p>Create a new model object and instantiate its RNG automatically.</p> Source code in <code>mesa/model.py</code> <pre><code>def __new__(cls, *args: Any, **kwargs: Any) -&gt; Any:\n    \"\"\"Create a new model object and instantiate its RNG automatically.\"\"\"\n    obj = object.__new__(cls)\n    obj._seed = kwargs.get(\"seed\")\n    if obj._seed is None:\n        # We explicitly specify the seed here so that we know its value in\n        # advance.\n        obj._seed = random.random()\n    obj.random = random.Random(obj._seed)\n    # TODO: Remove these 2 lines just before Mesa 3.0\n    obj._steps = 0\n    obj._time = 0\n    return obj\n</code></pre>"},{"location":"technical/api/inherited/#mesa.Model.get_agents_of_type","title":"<code>get_agents_of_type(agenttype)</code>","text":"<p>Retrieves an AgentSet containing all agents of the specified type.</p> Source code in <code>mesa/model.py</code> <pre><code>def get_agents_of_type(self, agenttype: type[Agent]) -&gt; AgentSet:\n    \"\"\"Retrieves an AgentSet containing all agents of the specified type.\"\"\"\n    return AgentSet(self.agents_[agenttype].keys(), self)\n</code></pre>"},{"location":"technical/api/inherited/#mesa.Model.next_id","title":"<code>next_id()</code>","text":"<p>Return the next unique ID for agents, increment current_id</p> Source code in <code>mesa/model.py</code> <pre><code>def next_id(self) -&gt; int:\n    \"\"\"Return the next unique ID for agents, increment current_id\"\"\"\n    self.current_id += 1\n    return self.current_id\n</code></pre>"},{"location":"technical/api/inherited/#mesa.Model.reset_randomizer","title":"<code>reset_randomizer(seed=None)</code>","text":"<p>Reset the model random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int | None</code> <p>A new seed for the RNG; if None, reset using the current seed</p> <code>None</code> Source code in <code>mesa/model.py</code> <pre><code>def reset_randomizer(self, seed: int | None = None) -&gt; None:\n    \"\"\"Reset the model random number generator.\n\n    Args:\n        seed: A new seed for the RNG; if None, reset using the current seed\n    \"\"\"\n\n    if seed is None:\n        seed = self._seed\n    self.random.seed(seed)\n    self._seed = seed\n</code></pre>"},{"location":"technical/api/inherited/#mesa.Model.run_model","title":"<code>run_model()</code>","text":"<p>Run the model until the end condition is reached. Overload as needed.</p> Source code in <code>mesa/model.py</code> <pre><code>def run_model(self) -&gt; None:\n    \"\"\"Run the model until the end condition is reached. Overload as\n    needed.\n    \"\"\"\n    while self.running:\n        self.step()\n</code></pre>"},{"location":"technical/api/inherited/#mesa.Model.step","title":"<code>step()</code>","text":"<p>A single step. Fill in here.</p> Source code in <code>mesa/model.py</code> <pre><code>def step(self) -&gt; None:\n    \"\"\"A single step. Fill in here.\"\"\"\n</code></pre>"},{"location":"technical/api/inherited/#-","title":"---","text":""},{"location":"technical/api/inherited/#mesa-base-agent-class","title":"Mesa Base Agent Class","text":"<p>Base class for a model agent in Mesa.</p> <p>Attributes:</p> Name Type Description <code>unique_id</code> <code>int</code> <p>A unique identifier for this agent.</p> <code>model</code> <code>Model</code> <p>A reference to the model instance.</p> <code>self.pos</code> <code>Model</code> <p>Position | None = None</p> Source code in <code>mesa/agent.py</code> <pre><code>class Agent:\n    \"\"\"\n    Base class for a model agent in Mesa.\n\n    Attributes:\n        unique_id (int): A unique identifier for this agent.\n        model (Model): A reference to the model instance.\n        self.pos: Position | None = None\n    \"\"\"\n\n    def __init__(self, unique_id: int, model: Model) -&gt; None:\n        \"\"\"\n        Create a new agent.\n\n        Args:\n            unique_id (int): A unique identifier for this agent.\n            model (Model): The model instance in which the agent exists.\n        \"\"\"\n        self.unique_id = unique_id\n        self.model = model\n        self.pos: Position | None = None\n\n        # register agent\n        try:\n            self.model.agents_[type(self)][self] = None\n        except AttributeError:\n            # model super has not been called\n            self.model.agents_ = defaultdict(dict)\n            self.model.agents_[type(self)][self] = None\n            self.model.agentset_experimental_warning_given = False\n\n            warnings.warn(\n                \"The Mesa Model class was not initialized. In the future, you need to explicitly initialize the Model by calling super().__init__() on initialization.\",\n                FutureWarning,\n                stacklevel=2,\n            )\n\n    def remove(self) -&gt; None:\n        \"\"\"Remove and delete the agent from the model.\"\"\"\n        with contextlib.suppress(KeyError):\n            self.model.agents_[type(self)].pop(self)\n\n    def step(self) -&gt; None:\n        \"\"\"A single step of the agent.\"\"\"\n\n    def advance(self) -&gt; None:\n        pass\n\n    @property\n    def random(self) -&gt; Random:\n        return self.model.random\n</code></pre>"},{"location":"technical/api/inherited/#mesa.Agent.__init__","title":"<code>__init__(unique_id, model)</code>","text":"<p>Create a new agent.</p> <p>Parameters:</p> Name Type Description Default <code>unique_id</code> <code>int</code> <p>A unique identifier for this agent.</p> required <code>model</code> <code>Model</code> <p>The model instance in which the agent exists.</p> required Source code in <code>mesa/agent.py</code> <pre><code>def __init__(self, unique_id: int, model: Model) -&gt; None:\n    \"\"\"\n    Create a new agent.\n\n    Args:\n        unique_id (int): A unique identifier for this agent.\n        model (Model): The model instance in which the agent exists.\n    \"\"\"\n    self.unique_id = unique_id\n    self.model = model\n    self.pos: Position | None = None\n\n    # register agent\n    try:\n        self.model.agents_[type(self)][self] = None\n    except AttributeError:\n        # model super has not been called\n        self.model.agents_ = defaultdict(dict)\n        self.model.agents_[type(self)][self] = None\n        self.model.agentset_experimental_warning_given = False\n\n        warnings.warn(\n            \"The Mesa Model class was not initialized. In the future, you need to explicitly initialize the Model by calling super().__init__() on initialization.\",\n            FutureWarning,\n            stacklevel=2,\n        )\n</code></pre>"},{"location":"technical/api/inherited/#mesa.Agent.remove","title":"<code>remove()</code>","text":"<p>Remove and delete the agent from the model.</p> Source code in <code>mesa/agent.py</code> <pre><code>def remove(self) -&gt; None:\n    \"\"\"Remove and delete the agent from the model.\"\"\"\n    with contextlib.suppress(KeyError):\n        self.model.agents_[type(self)].pop(self)\n</code></pre>"},{"location":"technical/api/inherited/#mesa.Agent.step","title":"<code>step()</code>","text":"<p>A single step of the agent.</p> Source code in <code>mesa/agent.py</code> <pre><code>def step(self) -&gt; None:\n    \"\"\"A single step of the agent.\"\"\"\n</code></pre>"},{"location":"de/mesa_docs/","title":"Mesa","text":"<p>F\u00fcr ausf\u00fchrlichere Informationen siehe die offizielle Mesa documentation.</p>"},{"location":"de/mesa_docs/#die-python-bibliothek-mesa-fur-agentenbasierte-modellierung","title":"Die Python-Bibliothek \"Mesa\" f\u00fcr agentenbasierte Modellierung","text":"<p>Mesa<sup>1</sup> ist eine Python-Bibliothek, die speziell f\u00fcr die Erstellung von agentenbasierten Modellen (ABMs)<sup>2</sup> entwickelt wurde.  Diese Modelle erm\u00f6glichen es, Individuen, sogenannte Agenten, innerhalb einer definierten Umgebung (dem Model) interagieren zu lassen.  Mesa bietet Werkzeuge zur Definition, Ausf\u00fchrung und Visualisierung solcher Modelle und Agenten.  Dies erm\u00f6glicht die Simulation komplexer Systeme sowie die Beobachtung emergenter Verhaltensweisen,  welche oft bereits aus sehr einfachen Regeln hervorgehen.</p>"},{"location":"de/mesa_docs/#agentenbasierte-modellierung-bei-der-untersuchung-komplexer-gesellschaftlicher-fragen","title":"Agentenbasierte Modellierung bei der Untersuchung komplexer gesellschaftlicher Fragen","text":"<p>Multi-Agenten-Simulationen bieten eine wertvolle Erg\u00e4nzung bei der Erforschung von Wahlregeln und kollektiven Entscheidungsprozessen.  Diese Methode erm\u00f6glicht die Modellierung sehr komplexer Interaktionen, die mit traditionellen Methoden schwer zu erfassen sind<sup>3</sup>.  Agentenbasierte Modelle dienen haupts\u00e4chlich der Erforschung und Analyse komplexer Zusammenh\u00e4nge.  Das Hauptaugenmerk liegt darauf zu verstehen, wie individuelle Verhaltensweisen und Interaktionen zu kollektiven Ergebnissen f\u00fchren.  Sie werden h\u00e4ufig in den Sozialwissenschaften, der Wirtschaftswissenschaft und der Umweltforschung eingesetzt,  um Szenarien zu modellieren und zu analysieren, die anderweitig schwer zu untersuchen sind.</p> <p> Bild 1: Beispiel eines simplen Schelling-Modells in Mesa</p> <ol> <li> <p>Jackie Kazil, David Masad, and Andrew Crooks. Utilizing Python for Agent-Based Modeling: The Mesa Framework. In: Social, Cultural, and Behavioral Modeling. Ed. by Robert Thomson, Halil Bisgin, Christopher Dancy, Ayaz Hyder, and Muhammad Hussain. Cham: Springer International Publishing, 2020, pp. 308\u2013317\u00a0\u21a9</p> </li> <li> <p>Dirk Helbing. Agent-based modeling. In: Social self-organization: Agent-based simulations and experiments to study emergent social behavior. Springer, 2012, pp. 25\u201370\u00a0\u21a9</p> </li> <li> <p>Robert L Axtell and J Doyne Farmer. Agent-based modeling in economics and finance: Past, present, and future. In: Journal of Economic Literature (2022), pp. 1\u201310\u00a0\u21a9</p> </li> </ol>"},{"location":"de/teaser/","title":"Zukunft gestalten: Demokratie-Forschung zur Bew\u00e4ltigung globaler Herausforderungen","text":"<p>In einer Welt voller Komplexit\u00e4t und Unsicherheit stehen wir an einem Scheideweg.  Dringende globale Herausforderungen wie der Klimawandel<sup>9</sup>, soziale Ungleichheit<sup>8</sup> und die ethischen Dilemmata<sup>4</sup>,  die mit dem rasanten Fortschritt k\u00fcnstlicher Intelligenz (KI) einhergehen, dr\u00e4ngen nach L\u00f6sungen.</p> <p>Eine Zukunft, in der KI die menschliche Intelligenz in vielen Bereichen \u00fcbertrifft, erscheint zunehmend wahrscheinlich<sup>3</sup>.  K\u00f6nnen wir diese Technologie sinnvoll und sicher in bestehende Governance-Verfahren und Strukturen integrieren?  Aktuelle KI arbeitet oft ohne ethische \u00dcberlegungen, erh\u00e4lt Vorurteile aufrecht<sup>5</sup>  und trifft Entscheidungen mit fragw\u00fcrdiger Transparenz und Weitsicht<sup>2</sup>. </p> <p>Wenn Sie eine einzige L\u00f6sung f\u00fcr die dringendsten Probleme der Welt nennen m\u00fcssten, welche w\u00e4re das?  Umfassende Bildung? Innovation und Technologie? Oder gar KI?</p>"},{"location":"de/teaser/#die-bedeutung-kollektiver-intelligenz","title":"Die Bedeutung kollektiver Intelligenz","text":"<p>Ich behaupte, dass die Verbesserung der gesellschaftlichen demokratischen Verwaltung (Governance) der Dreh- und Angelpunkt aller m\u00f6glichen L\u00f6sungen ist.  Mit anderen Worten: Wir m\u00fcssen kollektiv intelligenter<sup>6</sup> werden,  um unsere Zukunft sicher und effektiv zu gestalten.</p> <p>Mit dem Ausblick auf eine aufkommende Allgemeine KI gilt es mehr denn je, demokratische Selbstverwaltung zu st\u00e4rken, auszubauen und jegliche KI-Entwicklung symbiotisch in sie einzuhegen<sup>7</sup>.  Im Kern des KI-Dilemmas liegt die Notwendigkeit ethischer Entscheidungsfindung und strategischer Planung \u2013 also eben  jenes Bereichs, in dem die Schw\u00e4chen k\u00fcnstlicher Intelligenz am deutlichsten zutage treten.  Demokratische Selbstbestimmung von Menschen kann genau diese L\u00fccke f\u00fcllen.  Sie bietet die notwendigen Schranken und Kontrollen,  um KI-Entwicklung mit menschlichen Werten und langfristigem Wohlergehen in Einklang zu bringen.</p> <p></p> <p>Die Bedeutung demokratischer Entscheidungsfindung geht jedoch \u00fcber den Bereich der KI hinaus.  Sie erstreckt sich auf unsere kollektive Reaktion auf alle globalen Herausforderungen und stellt sicher,  dass politische Ma\u00dfnahmen inklusiv, koh\u00e4rent und rechenschaftspflichtig sind.  Demokratische Verwaltung f\u00f6rdert wirtschaftliche Stabilit\u00e4t,  soziale Gerechtigkeit und Umweltverantwortung \u2013 wesentliche Bestandteile,  um die Komplexit\u00e4ten des 21. Jahrhunderts zu bew\u00e4ltigen.</p>"},{"location":"de/teaser/#einsatz-von-multi-agenten-basierten-simulationen","title":"Einsatz von Multi-Agenten-basierten Simulationen","text":"<p>Um demokratische Prozesse zu verbessern, m\u00fcssen wir zun\u00e4chst in die Forschung eintauchen.  Traditionell konzentrierte sich die Erforschung kollektiver Entscheidungsfindung darauf,  Methoden anhand vern\u00fcnftig erscheinender Annahmen  (wie dem Pareto-Prinzip, Condorcet-Kriterium, Nicht-Diktatur usw.)  zu bewerten und schlie\u00dflich mathematisch zu beweisen, dass keine Methode jemals alle Kriterien erf\u00fcllen wird<sup>1</sup>.  Es handelt sich bei kollektiven Entscheidungen also bereits theoretisch um ein nicht-triviales Problem. Doch die wahre Komplexit\u00e4t kollektiver Entscheidungsfindung, n\u00e4mlich die im realen Kontext, in realen Gesellschaften, ist noch um einiges gr\u00f6\u00dfer.  Reale demokratische Verwaltung geht weit \u00fcber das blo\u00dfe Ineinklangbringen individueller Pr\u00e4ferenzen hinaus \u2013 sie  beinhaltet Pfadabh\u00e4ngigkeiten vergangener Entscheidungen, Desinformation und mangelnde Beteiligung,  um nur einige offensichtliche Herausforderungen zu nennen.</p> <p>Um diese Herausforderungen zu bew\u00e4ltigen, sind innovative Ans\u00e4tze erforderlich.  Das vorliegende Projekt zielt darauf ab, langfristig m\u00f6glichst viele dieser Einfl\u00fcsse durch Multi-Agenten-basierte  Simulationen integriert zu untersuchen.</p> <p>Das Modell und die Forschungsfragen einer Masterarbeit  k\u00f6nnen diesen Ansatz nat\u00fcrlich nur in ihren absoluten Grundz\u00fcgen darstellen.  Soweit uns bekannt, wurde dieser Ansatz noch nicht systematisch in der  Erforschung kollektiver Entscheidungsfindung angewandt, weshalb wir auch sehr grundlegend beginnen. Dennoch sollte das Potenzial von Multi-Agenten-basiertem Modellieren nicht untersch\u00e4tzt werden.  Langfristig wird dadurch sehr wahrscheinlich erm\u00f6glicht,  alle wesentlichen Aspekte der realen demokratischen Selbstverwaltung zu untersuchen<sup>10</sup>. Die kollektive Intelligenz einer Gesellschaft durch verbesserte Governance-Verfahren zu st\u00e4rken,  ist wahrscheinlich der effektivste Weg und unser gr\u00f6\u00dfter Hebel, die Herausforderungen unserer Zeit zu meistern.</p>"},{"location":"de/teaser/#quellen","title":"Quellen","text":"<ol> <li> <p>Felix Brandt, Vincent Conitzer, Ulle Endriss, J\u00e9r\u00f4me Lang, and Ariel D. Procaccia, editors. Handbook of Computational Social Choice. Cambridge University Press, 2016\u00a0\u21a9</p> </li> <li> <p>Jana Fehr, Brian Citro, Rohit Malpani, Christoph Lippert, and Vince I Madai. A trustworthy AI reality-check: the lack of transparency of artificial intelligence products in healthcare. Frontiers in Digital Health, 6:1267290, 2024.\u00a0\u21a9</p> </li> <li> <p>Katja Grace, John Salvatier, Allan Dafoe, Baobao Zhang, and Owain Evans. Viewpoint: When will AI exceed human performance? evidence from AI experts. J. Artif. Intell. Res., 62:729\u2013754, 2018.\u00a0\u21a9</p> </li> <li> <p>Benjamin Hilton. Preventing an AI-related catastrophe: AI might bring huge benefits \u2014 if we avoid the risks.\u00a0\u21a9</p> </li> <li> <p>Susan Leavy, Barry O\u2019Sullivan, and Eugenia Siapera. Data, power and bias in artificial intelligence. CoRR, abs/2008.07341, 2020.\u00a0\u21a9</p> </li> <li> <p>Jan Marco Leimeister. Collective intelligence. Business &amp; Information Systems Engineering, 2:245\u2013248, 2010.\u00a0\u21a9</p> </li> <li> <p>Thomas W Malone. Superminds: The surprising power of people and computers thinking together. Little, Brown Spark, 2018.\u00a0\u21a9</p> </li> <li> <p>Thomas Piketty. Das Kapital im 21. Jahrhundert. CH Beck, 2014.\u00a0\u21a9</p> </li> <li> <p>Hans-Otto P\u00f6rtner, Debra C Roberts, H Adams, C Adler, P Aldunce, E Ali, R Ara Begum, R Betts, R Bezner Kerr, R Biesbroek, et al. Climate change 2022: Impacts, adaptation and vulnerability. IPCC Sixth Assessment Report, 2022.\u00a0\u21a9</p> </li> <li> <p>Robert L Axtell and J Doyne Farmer. Agent-based modeling in economics and finance: Past, present, and future. In: Journal of Economic Literature (2022), pp. 1\u201310\u00a0\u21a9</p> </li> </ol>"},{"location":"de/QA/","title":"QA","text":""},{"location":"de/QA/#warum-ist-die-granularitat-so-grob-bzw-die-komplexitat-so-niedrig","title":"Warum ist die Granularit\u00e4t so grob, bzw. die Komplexit\u00e4t so niedrig?","text":"<p>Die Granularit\u00e4t ist weit weg von der Realit\u00e4t. Das ist Absicht und hat vor allem zwei Gr\u00fcnde.  Zum einen ist die Arbeit noch sehr grundlegend,  weil es in der Literatur zu simulativen Vergleichen von Wahlverfahren noch nicht viel gibt, auf dem eine h\u00f6ere Komplexit\u00e4t oder Granularit\u00e4t aufgebaut werden kann.  Zum zweiten schwindet mit einer h\u00f6heren Komplexit\u00e4t/Granularit\u00e4t sehr schnell die Interpretierbarkeit  (und m\u00f6glicherweise auch Reproduzierbarkeit).  In Simulationen k\u00f6nnen aber nicht selten schon anhand sehr einfacher Modelle unerwartete Effekte  und Mechanismen auftauchen.  Das ist auch hier die Hoffnung.</p>"},{"location":"de/QA/#was-ist-der-hauptkonflikt-den-die-simulation-untersucht","title":"Was ist der Hauptkonflikt, den die Simulation untersucht?","text":"<p>Der Hauptkonflikt ist die Teilnahme an der Wahl.  Da die einzelne Agentin zun\u00e4chst (auf kurze Sicht) i.d.R. nicht erwarten kann  ihre assets durch die Teilnahme zu steigern (au\u00dfer alle Agenten denken so  und die Wahlbeteiligung ist entsprechend niedrig),  hat sie einen Anreiz sich die Kosten zu sparen und auf die Teilnahme zu verzichten  (nach dem Motto \"meine Stimme macht eh keinen Unterschied, dann muss ich auch nicht abstimmen\").  Auf lange Sicht w\u00fcrde sich eine dauerhafte Nichtteilnahme aber vermutlich negativ f\u00fcr die Agentin auswirken,  da zu erwarten ist, dass sich die Umgebung entgegen ihrer Interessen entwickelt.</p> <p>Ein weiterer Konflikt ist die Abstimmung der Agentin selbst,  also ob sie vorrangig ihr Wissen f\u00fcr die tats\u00e4chliche Verteilung (der Farben) in die Abstimmung einbringt  (und damit allen hilft), oder eher ihren Interessen (eigenen Pr\u00e4ferenzen) nach abstimmt  (um einerseits selbst einen h\u00f6heren Anteil an der Belohnung zu bekommen  und andererseits die Umgebung zu ihren Gunsten zu beeinflussen). Ob sie also eher \"egoistisch\" oder eher \"altruistisch\" bzw. \"Gemeinwohl-orientiert\" abstimmt.</p>"},{"location":"de/QA/#wonach-wird-optimiert","title":"Wonach wird optimiert?","text":"<p>F\u00fcr die Partizipation gibt es hoffentlich kein leicht zu berechnendes Optimum,  da eine Simulation sonst \u00fcberfl\u00fcssig w\u00e4re, also das m\u00fcssen wir meinem Verst\u00e4ndnis nach verhindern  (in dem Fall m\u00fcssten wir das Modell komplexer machen).  Die Optimierungsfunktion f\u00fcr das Training der Agenten ist nicht ganz leicht zu l\u00f6sende Aufgabe.  Gut w\u00e4re, wenn es ausreichte, die eigene Belohnung zu maximieren,  weil das i.d.R. die Standardannahme ist.  Ob das ausreicht oder die Agenten Modelle dann zu simpel werden ist noch nicht klar.  Auf jeden Fall d\u00fcrfen die Agenten weder zu intelligent, noch zu simpel sein.  Vor allem weder zu kurz, noch zu weitsichtig.  Das d\u00fcrfte aber nicht nur eine Frage der Optimierungsfunktion sein,  sondern auch der genauen Ausgestaltung des Trainings und der Input-Variablen.  Auf jeden Fall ist das Training sehr wahrscheinlich der heikelste Part.</p>"},{"location":"de/QA/#wie-funktioniert-die-ausschuttung-der-belohnungen","title":"Wie funktioniert die Aussch\u00fcttung der Belohnung(en)?","text":"<ol> <li>N\u00e4he des Konsenses an der \"Realit\u00e4t\":     Jede Agentin (nicht nur die Teilnehmenden) erh\u00e4lt eine Belohnung b_1,     welche von dem Ergebnis der Wahl abh\u00e4ngt.     Je n\u00e4her das Ergebnis der Wahl (die durch die Wahl gesch\u00e4tzte H\u00e4ufigkeitsreihenfolge der Feldfarben)    an der tats\u00e4chlichen H\u00e4ufigkeitsreihenfolge der Feldfarben ist,    desto gr\u00f6\u00dfer b_1.</li> <li>N\u00e4he des Ergebnisses zur (fixen) pers\u00f6nlichen Pr\u00e4ferenz (Pers\u00f6nlichkeit):     Jede Agentin, bekommt eine Belohnung b_2     (wahrscheinlich mit 0 \u2264 b_2 \u2264 b_1 oder sogar -b_1 \u2264 b_2 \u2264 b_1),     je nachdem wie gut das Ergebnis mit ihrer fixen pers\u00f6nlichen Pr\u00e4ferenz     (also ihrer \"Pers\u00f6nlichkeit\", nicht der von ihr abgegebenen Pr\u00e4ferenz) \u00fcbereinstimmt.</li> </ol> <p>Dabei soll b_1 den Umstand abbilden, dass die Beteiligung an einer Wahl einen  (zwar eigentlich in seiner H\u00f6he sehr subjektiven, aber dennoch vorhandenen) Aufwand bedeutet. Und dass das Ergebnis bzw. die Folgen des Wahlausganges f\u00fcr alle Personen gleicherma\u00dfen g\u00fcltig sind, egal ob diese an der Wahl teilgenommen haben oder nicht.</p> <p>Durch b_2 soll die Tatsache abgebildet werden, dass die Agenten auch eigene Vorlieben oder Bed\u00fcrfnisse haben, dass also das Ergebnis f\u00fcr sie pers\u00f6nlich lebensqualit\u00e4tsbeeinflussend sein kann. Au\u00dferdem erm\u00f6glicht b_2 die konfliktive Situation,  dass die W\u00e4hlenden eine Abw\u00e4gung zwischen einer eher nach pers\u00f6nlicher Pr\u00e4ferenz gepr\u00e4gten Stimmabgabe und einer eher nach eigenem Wissen gepr\u00e4gten (tendenziell eher dem Gemeinwohl dienenden) Stimmabgabe treffen m\u00fcssen.</p>"},{"location":"de/QA/#welche-wahlverfahren-werden-untersucht","title":"Welche Wahlverfahren werden untersucht?","text":"<p>Die Wahl (und Anzahl) der Wahlverfahren steht noch nicht ganz fest. Im Moment ist geplant die folgenden Wahlverfahren zu untersuchen: - \"Plurality\" als Standardverfahren  - \"Approval-Voting\" da weitl\u00e4ufig als bestes Verfahren unter ComSoc-WissenschaftlerInnen angesehen - \"Kemeny\" (Ebenfalls oft als bestes Verfahren angesehen, allerdings NP-Schwer). </p> <p>Und m\u00f6glicherweise noch einige Standardverfahren.  Interessant w\u00e4ren auch \"exotischere\" (weniger gut mathematisch untersuchte oder verbreitete) Verfahren  wie \"Systemisches-Konsensieren\", \"liquid-democracy\"  oder repr\u00e4sentative Wahlverfahren (Wahl eines Gremiums) zu untersuchen. </p>"},{"location":"de/QA/#weitere-bzw-weiter-fuhrende-forschungsfragen","title":"Weitere bzw. weiter f\u00fchrende Forschungsfragen","text":"<p>Ebenfalls interessant w\u00e4re am Ende der Vergleiche zu untersuchen,  wie sich die Simulation ver\u00e4ndert, wenn stets ein fixer Anteil an Agenten zuf\u00e4llig bestimmt wird,  um (kostenlos oder sogar mit Aufwandsentsch\u00e4digung) an der Wahr teilzunehmen  (anstelle einer Freiwilligkeit welche mit Kosten verbunden ist).</p> <p>Des Weiteren k\u00f6nnte untersucht werden was passiert, wenn Agenten zus\u00e4tzliches \"Wissen\" (\u00fcber Feldfarben) kaufen  oder durch \"laufen\" bzw. springen \"erkunden\" k\u00f6nnen.</p>"}]}